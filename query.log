2016-12-07 at 17:29:11 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:38) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:116) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:27) [bin/:?]

2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-07 at 17:29:12 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-07 at 17:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-07 at 17:29:13 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-07 at 17:29:13 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-07 at 17:29:13 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x51f116b8 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-07 at 17:29:13 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x51f116b8 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x51f116b80x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-07 at 17:29:13 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-07 at 17:29:13 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-07 at 17:29:13 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,6,1c,0,0,0,10,69,ffffffd7,fffffff0,17,57,69,ffffffba,ffffffa9,24,ffffffff,ffffff9f,ffffffdb,4b,ffffffb8,16,43,0,]
2016-12-07 at 17:29:13 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d061c, negotiated timeout = 60000
2016-12-07 at 17:29:13 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x51f116b80x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-07 at 17:29:13 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x51f116b8-0x158d73a7f8d061c connected
2016-12-07 at 17:29:13 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d061c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,48259,0  request:: '/hbase/hbaseid,F  response:: s{712,43385,1480733758386,1481081201547,2,0,0,0,67,0,712} 
2016-12-07 at 17:29:13 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d061c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,48259,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030fffffff83affffffb2ffffffb93139454a50425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,43385,1480733758386,1481081201547,2,0,0,0,67,0,712} 
2016-12-07 at 17:29:13 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x51f116b8-0x158d73a7f8d061c, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-07 at 17:29:14 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7c137fd5, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-07 at 17:29:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d061c, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,48259,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,25,0,0,0,17,46605} 
2016-12-07 at 17:29:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d061c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,48259,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffbbfffffff1ffffffe2566affffffda324450425546a13a679696e676a6910ffffffe0ffffffd4318ffffff8cffffff99ffffffc6ffffffbaffffff8d2b10018ffffffeaffffffd43,s{43381,43381,1481081200442,1481081200442,0,0,0,97064038236487783,56,0,43381} 
2016-12-07 at 17:29:14 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x51f116b8-0x158d73a7f8d061c, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-07 at 17:29:14 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-07 at 17:29:14 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-07 at 17:29:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-07 at 17:29:14 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 116ms
2016-12-07 at 17:29:14 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 57ms
2016-12-07 at 17:29:14 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-07 at 17:29:14 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-07 at 17:29:14 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d061c
2016-12-07 at 17:29:14 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d061c
2016-12-07 at 17:29:14 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d061c
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d061c, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,48260,0  request:: null response:: null
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d061c : Unable to read additional data from server sessionid 0x158d73a7f8d061c, likely server has closed socket
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d061c
2016-12-07 at 17:29:15 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d061c closed
2016-12-07 at 17:29:15 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-07 at 17:29:15 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d061c
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x38089a5a opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-07 at 17:29:15 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x38089a5a connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-07 at 17:29:15 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x38089a5a0x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-07 at 17:29:15 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-07 at 17:29:15 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-07 at 17:29:15 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,6,1d,0,0,0,10,7c,fffffff8,ffffffea,17,fffffff7,ffffffb4,ffffff99,ffffffee,19,42,7,7,1e,41,2b,10,0,]
2016-12-07 at 17:29:15 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d061d, negotiated timeout = 60000
2016-12-07 at 17:29:15 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x38089a5a0x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d061d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,48261,0  request:: '/hbase/hbaseid,F  response:: s{712,43385,1480733758386,1481081201547,2,0,0,0,67,0,712} 
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d061d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,48261,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030fffffff83affffffb2ffffffb93139454a50425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,43385,1480733758386,1481081201547,2,0,0,0,67,0,712} 
2016-12-07 at 17:29:15 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x38089a5a-0x158d73a7f8d061d connected
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x38089a5a-0x158d73a7f8d061d, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-07 at 17:29:15 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@30e868be, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-07 at 17:29:15 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-07 at 17:29:15 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-07 at 17:29:15 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d061c
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,angelababy,99999999999999
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,angelababy,99999999999999'
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@7a1234bf
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d061d, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,48261,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d061d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,48261,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032306dffffff87ffffffcd48ffffffaa4973ffffff8c50425546a13a679696e676a6910fffffff4ffffffd4318ffffffacffffffa6ffffffc6ffffffbaffffff8d2b100183,s{43418,43418,1481081210673,1481081210673,0,0,0,0,60,0,43418} 
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x38089a5a-0x158d73a7f8d061d, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@7a1234bf; servers = yingji,60020,1481081197356 
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481081197356, seqNum=0]
2016-12-07 at 17:29:15 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-07 at 17:29:15 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 50ms
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481081197356, seqNum=13]
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 5ms
2016-12-07 at 17:29:15 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d061d
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d061d
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d061d
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d061d, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,48262,0  request:: null response:: null
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d061d : Unable to read additional data from server sessionid 0x158d73a7f8d061d, likely server has closed socket
2016-12-07 at 17:29:15 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d061d
2016-12-07 at 17:29:15 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d061d
2016-12-07 at 17:29:15 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d061d closed
2016-12-07 at 17:29:15 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-07 at 17:29:15 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-07 at 17:34:48 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:38) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:116) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:27) [bin/:?]

2016-12-07 at 17:34:48 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-07 at 17:34:48 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-07 at 17:34:48 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-07 at 17:34:48 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-07 at 17:34:48 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-07 at 17:34:48 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-07 at 17:34:48 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-07 at 17:34:48 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-07 at 17:34:48 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-07 at 17:34:49 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-07 at 17:34:49 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-07 at 17:34:49 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x51f116b8 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-07 at 17:34:49 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x51f116b8 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x51f116b80x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-07 at 17:34:49 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-07 at 17:34:49 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-07 at 17:34:49 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,6,34,0,0,0,10,34,fffffff1,63,17,56,ffffff80,ffffffa9,1e,21,46,4e,ffffffed,22,ffffff8c,3,7d,0,]
2016-12-07 at 17:34:49 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d0634, negotiated timeout = 60000
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x51f116b80x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-07 at 17:34:49 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x51f116b8-0x158d73a7f8d0634 connected
2016-12-07 at 17:34:49 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d0634, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,48336,0  request:: '/hbase/hbaseid,F  response:: s{712,43385,1480733758386,1481081201547,2,0,0,0,67,0,712} 
2016-12-07 at 17:34:49 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d0634, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,48336,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030fffffff83affffffb2ffffffb93139454a50425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,43385,1480733758386,1481081201547,2,0,0,0,67,0,712} 
2016-12-07 at 17:34:49 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x51f116b8-0x158d73a7f8d0634, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-07 at 17:34:50 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7c137fd5, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-07 at 17:34:50 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d0634, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,48336,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,25,0,0,0,17,46605} 
2016-12-07 at 17:34:50 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d0634, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,48336,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffbbfffffff1ffffffe2566affffffda324450425546a13a679696e676a6910ffffffe0ffffffd4318ffffff8cffffff99ffffffc6ffffffbaffffff8d2b10018ffffffeaffffffd43,s{43381,43381,1481081200442,1481081200442,0,0,0,97064038236487783,56,0,43381} 
2016-12-07 at 17:34:50 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x51f116b8-0x158d73a7f8d0634, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-07 at 17:34:50 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-07 at 17:34:50 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-07 at 17:34:50 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-07 at 17:34:50 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 191ms
2016-12-07 at 17:34:50 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 33ms
2016-12-07 at 17:34:50 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-07 at 17:34:50 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-07 at 17:34:50 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d0634
2016-12-07 at 17:34:50 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d0634
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d0634
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d0634, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,48337,0  request:: null response:: null
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d0634 : Unable to read additional data from server sessionid 0x158d73a7f8d0634, likely server has closed socket
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d0634
2016-12-07 at 17:34:51 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d0634 closed
2016-12-07 at 17:34:51 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-07 at 17:34:51 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d0634
2016-12-07 at 17:34:51 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-07 at 17:34:51 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-07 at 17:34:51 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d0634
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x38089a5a opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-07 at 17:34:51 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x38089a5a connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-07 at 17:34:51 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x38089a5a0x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-07 at 17:34:51 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-07 at 17:34:51 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-07 at 17:34:51 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,6,35,0,0,0,10,47,12,5e,17,fffffff6,ffffffcb,ffffff88,63,16,ffffff89,ffffffb5,18,fffffff5,14,18,4a,0,]
2016-12-07 at 17:34:51 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d0635, negotiated timeout = 60000
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d0635, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,48338,0  request:: '/hbase/hbaseid,F  response:: s{712,43385,1480733758386,1481081201547,2,0,0,0,67,0,712} 
2016-12-07 at 17:34:51 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x38089a5a0x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-07 at 17:34:51 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x38089a5a-0x158d73a7f8d0635 connected
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d0635, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,48338,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030fffffff83affffffb2ffffffb93139454a50425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,43385,1480733758386,1481081201547,2,0,0,0,67,0,712} 
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x38089a5a-0x158d73a7f8d0635, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-07 at 17:34:51 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@30e868be, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,angelababy,99999999999999
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,angelababy,99999999999999'
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@7a1234bf
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d0635, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,48338,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d0635, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,48338,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032306dffffff87ffffffcd48ffffffaa4973ffffff8c50425546a13a679696e676a6910fffffff4ffffffd4318ffffffacffffffa6ffffffc6ffffffbaffffff8d2b100183,s{43418,43418,1481081210673,1481081210673,0,0,0,0,60,0,43418} 
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x38089a5a-0x158d73a7f8d0635, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@7a1234bf; servers = yingji,60020,1481081197356 
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481081197356, seqNum=0]
2016-12-07 at 17:34:51 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-07 at 17:34:51 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 30ms
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481081197356, seqNum=13]
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 6ms
2016-12-07 at 17:34:51 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d0635
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d0635
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d0635
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d0635, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,48339,0  request:: null response:: null
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d0635 : Unable to read additional data from server sessionid 0x158d73a7f8d0635, likely server has closed socket
2016-12-07 at 17:34:51 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d0635
2016-12-07 at 17:34:51 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d0635
2016-12-07 at 17:34:51 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d0635 closed
2016-12-07 at 17:34:51 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-07 at 17:34:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 09:48:41 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.ListDirAll(HDFSTest.java:82) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:101) [bin/:?]

2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 09:48:42 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 09:48:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 09:52:55 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.ListDirAll(HDFSTest.java:83) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:102) [bin/:?]

2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 09:52:56 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 09:52:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.ListDirAll(HDFSTest.java:83) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:102) [bin/:?]

2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 09:57:19 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 09:57:19 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 09:57:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 09:57:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 09:57:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 09:57:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:16) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:42) [bin/:?]

2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:03:00 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:03:00 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:03:01 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:03:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:03:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:03:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:03:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:03:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:03:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:16) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:42) [bin/:?]

2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:22:02 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:22:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:29:19 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:16) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:42) [bin/:?]

2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:29:20 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:29:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:38) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:116) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:27) [bin/:?]

2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:29:45 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:29:45 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:29:46 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:29:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:29:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:29:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:29:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:29:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:29:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:29:46 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 10:29:46 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 10:29:46 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x1a4013 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 10:29:46 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x1a4013 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-core-2.6.0-mr1-cdh5.7.0.jar
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x1a40130x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 10:29:46 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 10:29:46 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 10:29:46 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2c,6b,0,0,0,10,31,ffffff80,65,36,ffffffa7,ffffffc3,48,ffffff98,71,62,ffffffb9,53,ffffffa2,52,fffffffb,6,0,]
2016-12-09 at 10:29:46 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2c6b, negotiated timeout = 60000
2016-12-09 at 10:29:46 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x1a40130x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 10:29:46 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x1a4013-0x158d73a7f8d2c6b connected
2016-12-09 at 10:29:46 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2c6b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,80216,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 10:29:46 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2c6b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,80216,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 10:29:46 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x1a4013-0x158d73a7f8d2c6b, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 10:29:47 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@14fc5f04, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 10:29:47 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2c6b, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,80216,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 10:29:47 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2c6b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,80216,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 10:29:47 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x1a4013-0x158d73a7f8d2c6b, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 10:29:47 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 10:29:47 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 10:29:47 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1193471756) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 10:29:47 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 104ms
2016-12-09 at 10:29:47 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 14ms
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 10:29:48 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 10:29:48 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2c6b
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2c6b
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2c6b
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2c6b, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,80217,0  request:: null response:: null
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2c6b : Unable to read additional data from server sessionid 0x158d73a7f8d2c6b, likely server has closed socket
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2c6b
2016-12-09 at 10:29:48 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2c6b closed
2016-12-09 at 10:29:48 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 10:29:48 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2c6b
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1193471756) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1193471756) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1193471756) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1193471756) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1193471756) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 10:29:48 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 10:29:48 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 10:29:48 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2c6b
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x42039326 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 10:29:48 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x42039326 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 10:29:48 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x420393260x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 10:29:48 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 10:29:48 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 10:29:48 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2c,6c,0,0,0,10,ffffff90,25,48,36,ffffffc7,3d,ffffffa5,fffffff0,3b,ffffffb1,ffffffbd,2c,ffffffc5,fffffffe,61,8,0,]
2016-12-09 at 10:29:48 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2c6c, negotiated timeout = 60000
2016-12-09 at 10:29:48 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x420393260x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2c6c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,80218,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 10:29:48 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x42039326-0x158d73a7f8d2c6c connected
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2c6c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,80218,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x42039326-0x158d73a7f8d2c6c, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 10:29:48 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@33308786, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,angelababy,99999999999999
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,angelababy,99999999999999'
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@503ecb24
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2c6c, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,80218,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2c6c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,80218,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x42039326-0x158d73a7f8d2c6c, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@503ecb24; servers = yingji,60020,1481249315144 
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 10:29:48 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 10:29:48 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1193471756) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 42ms
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 5ms
2016-12-09 at 10:29:48 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2c6c
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2c6c
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2c6c
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2c6c, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,80219,0  request:: null response:: null
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2c6c : Unable to read additional data from server sessionid 0x158d73a7f8d2c6c, likely server has closed socket
2016-12-09 at 10:29:48 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2c6c
2016-12-09 at 10:29:48 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2c6c
2016-12-09 at 10:29:48 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2c6c closed
2016-12-09 at 10:29:48 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1193471756) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1193471756) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1193471756) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1193471756) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 10:29:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1193471756) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:16) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:42) [bin/:?]

2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:30:09 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:30:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:16) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:42) [bin/:?]

2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:36:26 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:36:26 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:38:03 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:16) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:42) [bin/:?]

2016-12-09 at 10:38:03 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:38:03 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:38:03 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:38:03 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:38:03 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:38:04 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:38:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:38) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:116) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:27) [bin/:?]

2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:47:28 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:47:28 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:47:28 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 10:47:29 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 10:47:29 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x51f116b8 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 10:47:29 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x51f116b8 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x51f116b80x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 10:47:29 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 10:47:29 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 10:47:29 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2c,ffffffb1,0,0,0,10,39,ffffffda,4d,3b,fffffff0,ffffff8b,ffffff9f,5,71,69,67,b,ffffffba,fffffff1,ffffffd0,ffffff97,0,]
2016-12-09 at 10:47:29 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2cb1, negotiated timeout = 60000
2016-12-09 at 10:47:29 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x51f116b80x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 10:47:29 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x51f116b8-0x158d73a7f8d2cb1 connected
2016-12-09 at 10:47:29 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cb1, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,80441,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 10:47:29 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cb1, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,80441,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 10:47:29 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x51f116b8-0x158d73a7f8d2cb1, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 10:47:29 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7c137fd5, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 10:47:29 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cb1, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,80441,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 10:47:29 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cb1, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,80441,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 10:47:29 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x51f116b8-0x158d73a7f8d2cb1, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 10:47:30 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 10:47:30 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 144ms
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 59ms
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 10:47:30 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 10:47:30 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2cb1
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2cb1
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2cb1
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cb1, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,80442,0  request:: null response:: null
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2cb1
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2cb1 : Unable to read additional data from server sessionid 0x158d73a7f8d2cb1, likely server has closed socket
2016-12-09 at 10:47:30 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2cb1 closed
2016-12-09 at 10:47:30 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 10:47:30 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2cb1
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (4766562) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x38089a5a opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 10:47:30 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x38089a5a connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 10:47:30 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x38089a5a0x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 10:47:30 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 10:47:30 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 10:47:30 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2c,ffffffb2,0,0,0,10,0,77,5f,3b,10,ffffffa9,1,37,ffffff91,ffffffa0,31,ffffff89,3f,57,ffffff93,30,0,]
2016-12-09 at 10:47:30 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2cb2, negotiated timeout = 60000
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cb2, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,80443,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cb2, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,80443,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 10:47:30 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x38089a5a0x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x38089a5a0x0, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 10:47:30 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x38089a5a-0x158d73a7f8d2cb2 connected
2016-12-09 at 10:47:30 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@30e868be, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 10:47:30 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 10:47:30 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 10:47:30 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2cb1
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,angelababy,99999999999999
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,angelababy,99999999999999'
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@7a1234bf
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cb2, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,80443,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cb2, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,80443,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x38089a5a-0x158d73a7f8d2cb2, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@7a1234bf; servers = yingji,60020,1481249315144 
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 10:47:30 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 10:47:30 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 13ms
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 8ms
2016-12-09 at 10:47:30 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2cb2
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2cb2
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2cb2
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cb2, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,80444,0  request:: null response:: null
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2cb2 : Unable to read additional data from server sessionid 0x158d73a7f8d2cb2, likely server has closed socket
2016-12-09 at 10:47:30 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2cb2
2016-12-09 at 10:47:30 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2cb2 closed
2016-12-09 at 10:47:30 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2cb2
2016-12-09 at 10:47:30 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 10:47:30 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (4766562) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 10:47:42 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:16) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:42) [bin/:?]

2016-12-09 at 10:47:42 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:47:42 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:47:42 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:47:43 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:47:43 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:48:48 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 10:48:48 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:48:48 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:48:48 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:48:48 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:48:48 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:48:49 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:48:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:51:16 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:51:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:51:39 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 10:51:39 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:51:39 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:51:39 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:51:39 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:51:39 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:51:40 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:51:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 10:57:54 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 10:57:54 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 10:57:54 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 10:57:54 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 10:57:54 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 10:57:54 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 10:57:54 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 10:57:54 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 10:57:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 10:57:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 10:57:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 10:57:55 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 10:57:55 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 10:57:55 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 10:57:55 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 10:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 10:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 10:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 10:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 10:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 10:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:03:35 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:38) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:116) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:27) [bin/:?]

2016-12-09 at 11:03:35 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:03:35 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:03:35 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:03:35 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:03:35 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:03:35 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:03:35 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:03:35 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:03:35 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:03:35 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:03:36 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:03:36 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:03:36 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:03:36 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:03:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:03:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:03:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:03:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:03:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:03:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:03:36 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:03:36 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:03:36 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x4d910fd6 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:03:36 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x4d910fd6 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-4.0.0-incubating.jar
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x4d910fd60x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:03:36 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 11:03:36 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:04:20 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:38) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:116) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:27) [bin/:?]

2016-12-09 at 11:04:20 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:04:20 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:04:20 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:04:20 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:04:20 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:04:20 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:04:20 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:04:20 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:04:20 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:04:21 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:04:21 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:04:21 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x4d910fd6 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:04:21 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x4d910fd6 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x4d910fd60x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:04:21 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:04:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:04:21 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2c,fffffff7,0,0,0,10,26,61,ffffffca,39,2d,b,31,ffffffc7,ffffffaa,ffffffac,6,3c,49,38,1c,77,0,]
2016-12-09 at 11:04:21 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2cf7, negotiated timeout = 60000
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x4d910fd60x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:04:21 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x4d910fd6-0x158d73a7f8d2cf7 connected
2016-12-09 at 11:04:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cf7, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,80666,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:04:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cf7, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,80666,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:04:21 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x4d910fd6-0x158d73a7f8d2cf7, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:04:22 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@17bffc17, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:04:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cf7, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,80666,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 11:04:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cf7, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,80666,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 11:04:22 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x4d910fd6-0x158d73a7f8d2cf7, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:04:22 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 11:04:22 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 11:04:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1074263646) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 11:04:22 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 70ms
2016-12-09 at 11:04:22 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 9ms
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 11:04:23 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 11:04:23 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2cf7
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2cf7
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2cf7
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cf7, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,80667,0  request:: null response:: null
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2cf7
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2cf7 : Unable to read additional data from server sessionid 0x158d73a7f8d2cf7, likely server has closed socket
2016-12-09 at 11:04:23 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2cf7 closed
2016-12-09 at 11:04:23 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:04:23 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2cf7
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1074263646) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1074263646) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1074263646) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1074263646) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1074263646) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x2766ca9d opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:04:23 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x2766ca9d connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:04:23 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x2766ca9d0x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:04:23 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:04:23 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:04:23 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2c,fffffff8,0,0,0,10,ffffff85,6,ffffffad,39,4d,ffffff85,ffffff8d,1f,74,fffffffb,a,15,6c,ffffffe4,ffffff82,78,0,]
2016-12-09 at 11:04:23 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2cf8, negotiated timeout = 60000
2016-12-09 at 11:04:23 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x2766ca9d0x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:04:23 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 11:04:23 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cf8, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,80668,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:04:23 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2cf7
2016-12-09 at 11:04:23 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x2766ca9d-0x158d73a7f8d2cf8 connected
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cf8, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,80668,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x2766ca9d-0x158d73a7f8d2cf8, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:04:23 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@5460cf3a, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,angelababy,99999999999999
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,angelababy,99999999999999'
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@24111ef1
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cf8, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,80668,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cf8, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,80668,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x2766ca9d-0x158d73a7f8d2cf8, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@24111ef1; servers = yingji,60020,1481249315144 
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 11:04:23 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 11:04:23 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1074263646) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 24ms
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 4ms
2016-12-09 at 11:04:23 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2cf8
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2cf8
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2cf8
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2cf8, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,80669,0  request:: null response:: null
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2cf8 : Unable to read additional data from server sessionid 0x158d73a7f8d2cf8, likely server has closed socket
2016-12-09 at 11:04:23 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2cf8
2016-12-09 at 11:04:23 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2cf8
2016-12-09 at 11:04:23 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2cf8 closed
2016-12-09 at 11:04:23 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1074263646) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1074263646) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1074263646) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1074263646) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 11:04:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1074263646) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:04:37 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:04:37 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:05:02 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 11:05:02 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:05:02 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:05:02 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:05:02 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:05:02 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:05:03 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:05:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:06:52 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:06:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:08:05 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:38) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:116) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:27) [bin/:?]

2016-12-09 at 11:08:05 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:08:06 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:08:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:08:06 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:08:06 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:08:06 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x4d910fd6 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:08:06 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x4d910fd6 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x4d910fd60x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:08:07 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 11:08:07 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:08:29 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 11:08:29 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:08:30 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:08:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:16:31 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:16:31 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:16:53 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:16:53 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:17:23 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:17:24 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:17:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:17:47 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:17:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:30:10 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.InsertContactJava.insert_one(InsertContactJava.java:42) [bin/:?]
	at hbase.com.cn.InsertContactJava$1.run(InsertContactJava.java:30) [bin/:?]

2016-12-09 at 11:30:10 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:30:10 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:30:10 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:30:10 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:30:10 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:30:10 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:30:10 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:30:10 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:30:11 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:30:11 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:30:11 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:30:11 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x6f907002 opening connection to ZooKeeper ensemble=localhost:2181
2016-12-09 at 11:30:11 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x6f907002 connecting to ZooKeeper ensemble=localhost:2181
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x6f9070020x0, quorum=localhost:2181, baseZNode=/hbase
2016-12-09 at 11:30:11 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 11:30:11 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:11 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:11 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:11 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:12 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:12 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:12 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:12 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:12 CST DEBUG org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 272 retryOrThrow - Possibly transient ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
2016-12-09 at 11:30:12 CST TRACE org.apache.hadoop.hbase.util.RetryCounter 156 sleepUntilNextRetry - Sleeping 1000ms before retry #0...
2016-12-09 at 11:30:13 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:13 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:13 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:13 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:13 CST DEBUG org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 272 retryOrThrow - Possibly transient ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
2016-12-09 at 11:30:13 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:13 CST TRACE org.apache.hadoop.hbase.util.RetryCounter 156 sleepUntilNextRetry - Sleeping 2000ms before retry #1...
2016-12-09 at 11:30:13 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:13 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:13 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:14 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:14 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:14 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:14 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:14 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:14 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:14 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:14 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:15 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:15 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:15 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:15 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:15 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:15 CST DEBUG org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 272 retryOrThrow - Possibly transient ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
2016-12-09 at 11:30:15 CST TRACE org.apache.hadoop.hbase.util.RetryCounter 156 sleepUntilNextRetry - Sleeping 4000ms before retry #2...
2016-12-09 at 11:30:15 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:15 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:15 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:16 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:16 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:16 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:16 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:16 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:16 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:16 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:16 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:17 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:17 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:17 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:17 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:18 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:18 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:18 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:18 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:19 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:19 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:19 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:19 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:19 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:19 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:19 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:19 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:20 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:20 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:20 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:20 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:20 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:20 CST DEBUG org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 272 retryOrThrow - Possibly transient ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
2016-12-09 at 11:30:20 CST TRACE org.apache.hadoop.hbase.util.RetryCounter 156 sleepUntilNextRetry - Sleeping 8000ms before retry #3...
2016-12-09 at 11:30:20 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:20 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:20 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:21 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:21 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:21 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:21 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:21 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:30:21 CST WARN  org.apache.zookeeper.ClientCnxn$SendThread 1162 run - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_40]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:21 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 203 cleanup - Ignoring exception during shutdown input java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:30:21 CST DEBUG org.apache.zookeeper.ClientCnxnSocketNIO 210 cleanup - Ignoring exception during shutdown output java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797) ~[?:1.8.0_40]
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410) ~[?:1.8.0_40]
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170) [zookeeper-3.4.9.jar:3.4.9-1757313]

2016-12-09 at 11:33:00 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:38) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:116) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:27) [bin/:?]

2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:33:01 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:33:01 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:33:01 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:33:01 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:33:01 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:33:01 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 11:33:01 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:33:01 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 11:33:02 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:33:02 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:33:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:33:02 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,6b,0,0,0,10,17,6d,44,3c,ffffffb2,23,fffffffd,ffffffb8,35,6d,76,ffffffec,2,7f,72,fffffff2,0,]
2016-12-09 at 11:33:02 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2d6b, negotiated timeout = 60000
2016-12-09 at 11:33:02 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:33:02 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2d6b connected
2016-12-09 at 11:33:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d6b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81042,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:33:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d6b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81042,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:33:02 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2d6b, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:33:02 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:33:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d6b, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,81042,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 11:33:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d6b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81042,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 11:33:02 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2d6b, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:33:03 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 11:33:03 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 75ms
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 10ms
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 11:33:03 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 11:33:03 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2d6b
2016-12-09 at 11:33:03 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2d6b
2016-12-09 at 11:33:03 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2d6b
2016-12-09 at 11:33:03 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d6b, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81043,0  request:: null response:: null
2016-12-09 at 11:33:03 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2d6b
2016-12-09 at 11:33:03 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2d6b : Unable to read additional data from server sessionid 0x158d73a7f8d2d6b, likely server has closed socket
2016-12-09 at 11:33:03 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2d6b closed
2016-12-09 at 11:33:03 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:33:03 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2d6b
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:33:03 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:33:03 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:33:03 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 11:33:03 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 11:33:03 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2d6b
2016-12-09 at 11:33:03 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:33:03 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:33:03 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:33:03 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,6c,0,0,0,10,77,12,27,3c,ffffffd1,ffffff9d,59,11,ffffffff,ffffffbb,7a,ffffffc5,24,2b,ffffffd9,fffffff3,0,]
2016-12-09 at 11:33:03 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2d6c, negotiated timeout = 60000
2016-12-09 at 11:33:03 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:33:03 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2d6c connected
2016-12-09 at 11:33:03 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d6c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81044,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:33:03 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d6c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81044,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2d6c, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:33:03 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,sdzw,99999999999999
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,sdzw,99999999999999'
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22
2016-12-09 at 11:33:03 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d6c, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,81044,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 11:33:03 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d6c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81044,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2d6c, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22; servers = yingji,60020,1481249315144 
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 11:33:03 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 11:33:03 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 22ms
2016-12-09 at 11:33:03 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 11:33:04 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 11:33:04 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 23ms
2016-12-09 at 11:33:04 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2d6c
2016-12-09 at 11:33:04 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2d6c
2016-12-09 at 11:33:04 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2d6c
2016-12-09 at 11:33:04 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d6c, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81045,0  request:: null response:: null
2016-12-09 at 11:33:04 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2d6c : Unable to read additional data from server sessionid 0x158d73a7f8d2d6c, likely server has closed socket
2016-12-09 at 11:33:04 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2d6c
2016-12-09 at 11:33:04 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2d6c closed
2016-12-09 at 11:33:04 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2d6c
2016-12-09 at 11:33:04 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:33:04 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 11:33:04 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:33:04 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 11:33:04 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 11:33:04 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:41) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:119) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:35:32 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:35:32 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:35:32 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:35:32 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:35:32 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:35:32 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:35:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:35:32 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,77,0,0,0,10,ffffff99,ffffffd7,ffffffb9,3c,32,3b,ffffff8b,57,d,32,65,ffffff88,79,ffffffce,ffffffd7,ffffffec,0,]
2016-12-09 at 11:35:32 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2d77, negotiated timeout = 60000
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:35:32 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2d77 connected
2016-12-09 at 11:35:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d77, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81077,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:35:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d77, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81077,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:35:32 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2d77, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:35:33 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d77, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,81077,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d77, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81077,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2d77, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:35:33 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 11:35:33 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 67ms
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 12ms
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 11:35:33 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 11:35:33 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2d77
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2d77
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2d77
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d77, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81078,0  request:: null response:: null
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2d77 : Unable to read additional data from server sessionid 0x158d73a7f8d2d77, likely server has closed socket
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2d77
2016-12-09 at 11:35:33 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2d77 closed
2016-12-09 at 11:35:33 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2d77
2016-12-09 at 11:35:33 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:35:33 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:35:33 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:35:33 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:35:33 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:35:33 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,78,0,0,0,10,fffffff9,7c,ffffff9c,3c,52,ffffffb5,ffffffe7,ffffffaf,ffffffd7,ffffff80,69,61,ffffff9b,7a,3e,ffffffee,0,]
2016-12-09 at 11:35:33 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2d78, negotiated timeout = 60000
2016-12-09 at 11:35:33 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d78, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81079,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:35:33 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2d78 connected
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d78, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81079,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2d78, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:35:33 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:35:33 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 11:35:33 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 11:35:33 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2d77
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,sdzw,99999999999999
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,sdzw,99999999999999'
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d78, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,81079,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 11:35:33 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d78, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81079,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2d78, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:35:33 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22; servers = yingji,60020,1481249315144 
2016-12-09 at 11:35:34 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 11:35:34 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 11:35:34 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 11:35:34 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 11:35:34 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 28ms
2016-12-09 at 11:35:34 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 11:35:34 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 11:35:34 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 12ms
2016-12-09 at 11:35:34 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2d78
2016-12-09 at 11:35:34 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2d78
2016-12-09 at 11:35:34 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2d78
2016-12-09 at 11:35:34 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d78, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81080,0  request:: null response:: null
2016-12-09 at 11:35:34 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2d78 : Unable to read additional data from server sessionid 0x158d73a7f8d2d78, likely server has closed socket
2016-12-09 at 11:35:34 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2d78
2016-12-09 at 11:35:34 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2d78
2016-12-09 at 11:35:34 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2d78 closed
2016-12-09 at 11:35:34 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:35:34 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 11:35:34 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:35:34 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 11:35:34 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 11:35:34 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:42) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:120) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:36:53 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:36:53 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:36:54 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:36:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:36:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:36:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:36:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:36:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:36:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:36:54 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:36:54 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:36:54 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:36:54 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:36:54 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:36:54 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:36:54 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,7d,0,0,0,10,58,22,7f,3c,72,2f,44,8,ffffffa1,ffffffcf,6d,3a,ffffffbd,26,ffffffa5,ffffffef,0,]
2016-12-09 at 11:36:54 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2d7d, negotiated timeout = 60000
2016-12-09 at 11:36:54 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:36:54 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2d7d connected
2016-12-09 at 11:36:54 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81094,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:36:54 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81094,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:36:54 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2d7d, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:36:55 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7d, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,81094,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81094,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2d7d, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:36:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 11:36:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 74ms
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 14ms
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 11:36:55 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 11:36:55 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2d7d
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2d7d
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2d7d
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7d, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81095,0  request:: null response:: null
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2d7d : Unable to read additional data from server sessionid 0x158d73a7f8d2d7d, likely server has closed socket
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2d7d
2016-12-09 at 11:36:55 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2d7d closed
2016-12-09 at 11:36:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:36:55 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2d7d
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:36:55 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:36:55 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:36:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:36:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:36:55 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,7e,0,0,0,10,1f,ffffffbf,ffffff90,3c,ffffff92,4c,ffffffa6,39,ffffffc1,6,38,ffffffb8,42,ffffff8c,67,ffffff88,0,]
2016-12-09 at 11:36:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2d7e, negotiated timeout = 60000
2016-12-09 at 11:36:55 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:36:55 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2d7e connected
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7e, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81096,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7e, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81096,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2d7e, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:36:55 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:36:55 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 11:36:55 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 11:36:55 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2d7d
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,wangchengzhi,99999999999999
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,wangchengzhi,99999999999999'
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@62ef27a8
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7e, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,81096,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 11:36:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7e, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81096,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2d7e, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@62ef27a8; servers = yingji,60020,1481249315144 
2016-12-09 at 11:36:55 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 11:36:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 11:36:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 12ms
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Multi, callTime: 28ms
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Multi, callTime: 35ms
2016-12-09 at 11:36:56 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2d7e
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2d7e
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2d7e
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7e, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81097,0  request:: null response:: null
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2d7e : Unable to read additional data from server sessionid 0x158d73a7f8d2d7e, likely server has closed socket
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2d7e
2016-12-09 at 11:36:56 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2d7e closed
2016-12-09 at 11:36:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:36:56 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2d7e
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x43f82e78 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:36:56 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x43f82e78 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:36:56 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x43f82e780x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:36:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:36:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:36:56 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,7f,0,0,0,10,32,ffffffe0,ffffff8a,3c,32,ffffff98,ffffff85,7e,ffffffb6,49,ffffff9f,ffffffe3,16,15,7c,55,0,]
2016-12-09 at 11:36:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2d7f, negotiated timeout = 60000
2016-12-09 at 11:36:56 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x43f82e780x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:36:56 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x43f82e78-0x158d73a7f8d2d7f connected
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81098,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81098,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x43f82e78-0x158d73a7f8d2d7f, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:36:56 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@e54303, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,wangchengzhi,99999999999999
2016-12-09 at 11:36:56 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 11:36:56 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 11:36:56 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2d7e
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,wangchengzhi,99999999999999'
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@2f40e5db
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7f, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,81098,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7f, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81098,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x43f82e78-0x158d73a7f8d2d7f, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@2f40e5db; servers = yingji,60020,1481249315144 
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 11:36:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 11:36:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 12ms
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 14ms
2016-12-09 at 11:36:56 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2d7f
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2d7f
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2d7f
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2d7f, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81099,0  request:: null response:: null
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2d7f : Unable to read additional data from server sessionid 0x158d73a7f8d2d7f, likely server has closed socket
2016-12-09 at 11:36:56 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2d7f
2016-12-09 at 11:36:56 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2d7f closed
2016-12-09 at 11:36:56 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2d7f
2016-12-09 at 11:36:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 11:36:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:42) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:120) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:46:55 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:46:55 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:46:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:46:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:46:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:46:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:46:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:46:56 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:46:56 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:46:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:46:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:46:56 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:46:56 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:46:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:46:56 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,ffffffab,0,0,0,10,ffffffc4,ffffff9e,ffffffab,40,ffffffb9,6b,ffffff84,11,49,35,4,5f,49,ffffffe0,b,23,0,]
2016-12-09 at 11:46:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2dab, negotiated timeout = 60000
2016-12-09 at 11:46:56 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:46:56 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2dab connected
2016-12-09 at 11:46:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dab, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81235,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:46:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dab, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81235,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:46:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2dab, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:46:56 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:46:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dab, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,81235,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 11:46:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dab, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81235,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2dab, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:46:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 11:46:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 91ms
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 20ms
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 11:46:57 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 11:46:57 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2dab
2016-12-09 at 11:46:57 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2dab
2016-12-09 at 11:46:57 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2dab
2016-12-09 at 11:46:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dab, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81236,0  request:: null response:: null
2016-12-09 at 11:46:57 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2dab
2016-12-09 at 11:46:57 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2dab closed
2016-12-09 at 11:46:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:46:57 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2dab
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:46:57 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:46:57 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:46:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:46:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:46:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:46:57 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,ffffffac,0,0,0,10,24,44,ffffff8e,40,ffffffd9,ffffffe5,ffffffe0,69,13,ffffff84,8,38,6b,ffffff8c,72,24,0,]
2016-12-09 at 11:46:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2dac, negotiated timeout = 60000
2016-12-09 at 11:46:57 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:46:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dac, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81237,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:46:57 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2dac connected
2016-12-09 at 11:46:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dac, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81237,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2dac, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:46:57 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:46:57 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 11:46:57 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 11:46:57 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2dab
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,lidasheng,99999999999999
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,lidasheng,99999999999999'
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@62ef27a8
2016-12-09 at 11:46:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dac, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,81237,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 11:46:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dac, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81237,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2dac, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@62ef27a8; servers = yingji,60020,1481249315144 
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 11:46:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 11:46:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 12ms
2016-12-09 at 11:46:57 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Multi, callTime: 33ms
2016-12-09 at 11:46:58 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2dac
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2dac
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2dac
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dac, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81238,0  request:: null response:: null
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2dac : Unable to read additional data from server sessionid 0x158d73a7f8d2dac, likely server has closed socket
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2dac
2016-12-09 at 11:46:58 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2dac closed
2016-12-09 at 11:46:58 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:46:58 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2dac
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x32f232a5 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:46:58 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x32f232a5 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:46:58 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x32f232a50x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:46:58 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:46:58 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 11:46:58 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 11:46:58 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2dac
2016-12-09 at 11:46:58 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:46:58 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,ffffffad,0,0,0,10,37,65,ffffff88,40,79,31,ffffffc0,ffffffae,8,ffffffc7,6f,63,3f,15,ffffff87,fffffff1,0,]
2016-12-09 at 11:46:58 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2dad, negotiated timeout = 60000
2016-12-09 at 11:46:58 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x32f232a50x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:46:58 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x32f232a5-0x158d73a7f8d2dad connected
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dad, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81239,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dad, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81239,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x32f232a5-0x158d73a7f8d2dad, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:46:58 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@43f82e78, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,wangchengzhi,99999999999999
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,wangchengzhi,99999999999999'
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@2dc995f4
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dad, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,81239,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dad, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81239,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x32f232a5-0x158d73a7f8d2dad, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@2dc995f4; servers = yingji,60020,1481249315144 
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 11:46:58 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 11:46:58 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 24ms
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 12ms
2016-12-09 at 11:46:58 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2dad
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2dad
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2dad
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dad, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81240,0  request:: null response:: null
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2dad : Unable to read additional data from server sessionid 0x158d73a7f8d2dad, likely server has closed socket
2016-12-09 at 11:46:58 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2dad
2016-12-09 at 11:46:58 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2dad closed
2016-12-09 at 11:46:58 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2dad
2016-12-09 at 11:46:58 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 11:46:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:42) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:120) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:47:10 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:47:10 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:47:10 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:47:10 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:47:10 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:47:10 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 11:47:10 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:47:10 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 11:47:11 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:47:11 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:47:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:47:11 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,ffffffb0,0,0,0,10,d,ffffffa6,32,41,5a,ffffffa0,74,ffffffe1,40,31,ffffffbd,78,45,ffffff95,33,ffffffb6,0,]
2016-12-09 at 11:47:11 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2db0, negotiated timeout = 60000
2016-12-09 at 11:47:11 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:47:11 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2db0 connected
2016-12-09 at 11:47:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2db0, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81249,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:47:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2db0, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81249,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:47:11 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2db0, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:47:11 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:47:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2db0, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,81249,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 11:47:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2db0, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81249,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 11:47:11 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2db0, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:47:11 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 11:47:11 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 11:47:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 11:47:11 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 71ms
2016-12-09 at 11:47:11 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 13ms
2016-12-09 at 11:47:11 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 11:47:11 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 11:47:11 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2db0
2016-12-09 at 11:47:11 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2db0
2016-12-09 at 11:47:11 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2db0
2016-12-09 at 11:47:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2db0, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81255,0  request:: null response:: null
2016-12-09 at 11:47:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2db0 : Unable to read additional data from server sessionid 0x158d73a7f8d2db0, likely server has closed socket
2016-12-09 at 11:47:11 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2db0
2016-12-09 at 11:47:11 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2db0
2016-12-09 at 11:47:11 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2db0 closed
2016-12-09 at 11:47:11 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:47:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 11:47:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:47:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 11:47:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 11:47:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:47:12 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:47:12 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:47:12 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:47:12 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:47:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:47:12 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 11:47:12 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 11:47:12 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2db0
2016-12-09 at 11:47:12 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,ffffffb3,0,0,0,10,fffffffa,ffffff84,38,41,ffffffba,54,ffffff95,ffffff9c,4b,ffffffee,55,4d,72,c,1f,ffffffe9,0,]
2016-12-09 at 11:47:12 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2db3, negotiated timeout = 60000
2016-12-09 at 11:47:12 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:47:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2db3, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81256,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:47:12 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2db3 connected
2016-12-09 at 11:47:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2db3, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81256,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2db3, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:47:12 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,lidasheng,99999999999999
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,lidasheng,99999999999999'
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22
2016-12-09 at 11:47:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2db3, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,81256,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 11:47:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2db3, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81256,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2db3, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22; servers = yingji,60020,1481249315144 
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 11:47:12 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 11:47:12 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 9ms
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 6ms
2016-12-09 at 11:47:12 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2db3
2016-12-09 at 11:47:12 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2db3
2016-12-09 at 11:47:12 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2db3
2016-12-09 at 11:47:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2db3, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81257,0  request:: null response:: null
2016-12-09 at 11:47:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2db3 : Unable to read additional data from server sessionid 0x158d73a7f8d2db3, likely server has closed socket
2016-12-09 at 11:47:12 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2db3
2016-12-09 at 11:47:12 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2db3
2016-12-09 at 11:47:12 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2db3 closed
2016-12-09 at 11:47:12 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 11:47:12 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 11:52:48 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:42) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:120) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:52:49 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:52:49 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:52:49 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:52:50 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:52:50 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:52:50 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:52:50 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:52:50 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:52:50 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,ffffffc8,0,0,0,10,3a,ffffffe2,ffffffe9,3f,58,2b,4d,fffffff2,ffffffe5,ffffffd6,53,fffffff7,ffffff91,ffffff83,ffffffb1,ffffff92,0,]
2016-12-09 at 11:52:50 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2dc8, negotiated timeout = 60000
2016-12-09 at 11:52:50 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:52:50 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2dc8 connected
2016-12-09 at 11:52:50 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dc8, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81323,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:52:50 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dc8, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81323,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:52:50 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2dc8, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:52:50 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:52:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dc8, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,81323,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 11:52:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dc8, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81323,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2dc8, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:52:51 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 11:52:51 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 117ms
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 19ms
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 11:52:51 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 11:52:51 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2dc8
2016-12-09 at 11:52:51 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2dc8
2016-12-09 at 11:52:51 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2dc8
2016-12-09 at 11:52:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dc8, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81324,0  request:: null response:: null
2016-12-09 at 11:52:51 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2dc8
2016-12-09 at 11:52:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2dc8 : Unable to read additional data from server sessionid 0x158d73a7f8d2dc8, likely server has closed socket
2016-12-09 at 11:52:51 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2dc8 closed
2016-12-09 at 11:52:51 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 11:52:51 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2dc8
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:52:51 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:52:51 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:52:51 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:52:51 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:52:51 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 11:52:51 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 11:52:51 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2dc8
2016-12-09 at 11:52:51 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:52:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:52:51 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,ffffffc9,0,0,0,10,4d,3,ffffffe4,3f,fffffff8,76,2c,37,ffffffdb,19,ffffffbb,22,64,c,ffffffc6,5f,0,]
2016-12-09 at 11:52:51 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2dc9, negotiated timeout = 60000
2016-12-09 at 11:52:51 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:52:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dc9, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81325,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:52:51 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2dc9 connected
2016-12-09 at 11:52:51 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dc9, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81325,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2dc9, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:52:52 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,lidasheng,99999999999999
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,lidasheng,99999999999999'
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@62ef27a8
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dc9, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,81325,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dc9, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81325,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2dc9, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@62ef27a8; servers = yingji,60020,1481249315144 
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 11:52:52 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 11:52:52 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 39ms
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Multi, callTime: 30ms
2016-12-09 at 11:52:52 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2dc9
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2dc9
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2dc9
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dc9, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81326,0  request:: null response:: null
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2dc9 : Unable to read additional data from server sessionid 0x158d73a7f8d2dc9, likely server has closed socket
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2dc9
2016-12-09 at 11:52:52 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2dc9 closed
2016-12-09 at 11:52:52 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:52:52 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2dc9
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: stopped with 0 pending request(s)
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x32f232a5 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:52:52 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x32f232a5 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:52:52 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x32f232a50x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:52:52 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:52:52 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:52:52 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,ffffffca,0,0,0,10,14,ffffffa0,fffffff5,3f,18,ffffff94,ffffff8e,68,fffffffb,50,ffffff85,ffffffa0,ffffffe9,71,ffffff88,fffffff8,0,]
2016-12-09 at 11:52:52 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2dca, negotiated timeout = 60000
2016-12-09 at 11:52:52 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x32f232a50x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dca, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81327,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:52:52 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x32f232a5-0x158d73a7f8d2dca connected
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dca, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81327,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x32f232a5-0x158d73a7f8d2dca, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:52:52 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@43f82e78, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:52:52 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 11:52:52 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 11:52:52 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2dc9
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,lidasheng,99999999999999
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,lidasheng,99999999999999'
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@2dc995f4
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dca, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,81327,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dca, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81327,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x32f232a5-0x158d73a7f8d2dca, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@2dc995f4; servers = yingji,60020,1481249315144 
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 11:52:52 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 11:52:52 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 19ms
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 13ms
2016-12-09 at 11:52:52 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2dca
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2dca
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2dca
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2dca, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81328,0  request:: null response:: null
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2dca : Unable to read additional data from server sessionid 0x158d73a7f8d2dca, likely server has closed socket
2016-12-09 at 11:52:52 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2dca
2016-12-09 at 11:52:52 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2dca
2016-12-09 at 11:52:52 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2dca closed
2016-12-09 at 11:52:52 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 11:52:52 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:43) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:121) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:57:24 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 11:57:24 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 11:57:24 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:57:24 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:57:24 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:57:24 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 11:57:24 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:57:24 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 11:57:25 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:57:25 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:57:25 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:57:25 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,ffffffdf,0,0,0,10,42,34,36,40,39,54,fffffff6,72,71,70,15,ffffffc3,ffffffd1,ffffff90,ffffffa6,28,0,]
2016-12-09 at 11:57:25 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2ddf, negotiated timeout = 60000
2016-12-09 at 11:57:25 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:57:25 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2ddf connected
2016-12-09 at 11:57:25 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ddf, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81394,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:57:25 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ddf, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81394,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:57:25 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2ddf, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:57:25 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:57:25 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ddf, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,81394,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 11:57:25 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ddf, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81394,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 11:57:25 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2ddf, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:57:25 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 11:57:26 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 67ms
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 13ms
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 11:57:26 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 11:57:26 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2ddf
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2ddf
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2ddf
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ddf, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81395,0  request:: null response:: null
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2ddf : Unable to read additional data from server sessionid 0x158d73a7f8d2ddf, likely server has closed socket
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2ddf
2016-12-09 at 11:57:26 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2ddf
2016-12-09 at 11:57:26 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2ddf closed
2016-12-09 at 11:57:26 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:57:26 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 11:57:26 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 11:57:26 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 11:57:26 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 11:57:26 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2d,ffffffe0,0,0,0,10,5,fffffffc,5c,3f,57,42,3c,67,ffffffe3,1d,2,9,68,57,ffffff9e,ffffffcc,0,]
2016-12-09 at 11:57:26 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2de0, negotiated timeout = 60000
2016-12-09 at 11:57:26 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 11:57:26 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 11:57:26 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2de0 connected
2016-12-09 at 11:57:26 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 11:57:26 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2ddf
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2de0, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,81396,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2de0, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,81396,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2de0, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 11:57:26 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=member, startRow=
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,,99999999999999
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,,99999999999999'
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@6c0d9d86
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2de0, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,81396,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2de0, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,81396,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2de0, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@6c0d9d86; servers = yingji,60020,1481249315144 
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 11:57:26 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 11:57:26 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 35ms
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 16ms
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=708 associated with replica=0
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 2ms
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=708 associated with replica=0
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 615 getResultsToAddToCache - number results from RPC: 4,partial != null: false,number of partials so far: 0
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 143 call - Closing scanner id=708
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 2ms
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 280 nextScanner - Finished {ENCODED => 9a820ae0d288bfb8c904d2deb3149dbb, NAME => 'member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb.', STARTKEY => '', ENDKEY => ''}
2016-12-09 at 11:57:26 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2de0
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2de0
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2de0
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2de0, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,81397,0  request:: null response:: null
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2de0
2016-12-09 at 11:57:26 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2de0 : Unable to read additional data from server sessionid 0x158d73a7f8d2de0, likely server has closed socket
2016-12-09 at 11:57:26 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2de0 closed
2016-12-09 at 11:57:26 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 11:57:26 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2de0
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 11:57:26 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 13:33:11 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:43) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:121) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 13:33:11 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 13:33:11 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 13:33:12 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 13:33:12 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 13:33:12 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 13:33:12 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:33:12 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 13:33:12 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 13:33:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 13:33:12 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,5f,0,0,0,10,2,ffffffe4,ffffff88,31,1f,64,33,ffffffa1,ffffff86,ffffffd5,3c,45,ffffffe4,ffffffa1,fffffffc,ffffffdb,0,]
2016-12-09 at 13:33:12 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2f5f, negotiated timeout = 60000
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 13:33:12 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2f5f connected
2016-12-09 at 13:33:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f5f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,82637,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:33:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f5f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,82637,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:33:12 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2f5f, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 13:33:13 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 13:33:13 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f5f, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,82637,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 13:33:13 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f5f, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,82637,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 13:33:13 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2f5f, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 13:33:13 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 13:33:13 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 13:33:13 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 13:33:13 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 76ms
2016-12-09 at 13:33:13 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 24ms
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 13:33:14 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 13:33:14 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2f5f
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2f5f
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2f5f
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f5f, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,82638,0  request:: null response:: null
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2f5f : Unable to read additional data from server sessionid 0x158d73a7f8d2f5f, likely server has closed socket
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2f5f
2016-12-09 at 13:33:14 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2f5f closed
2016-12-09 at 13:33:14 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2f5f
2016-12-09 at 13:33:14 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:33:14 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:33:14 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 13:33:14 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 13:33:14 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 13:33:14 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 13:33:14 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 13:33:14 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2f5f
2016-12-09 at 13:33:14 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,60,0,0,0,10,ffffffc5,ffffffab,ffffffaf,30,3d,52,79,ffffff95,fffffff7,ffffff82,29,ffffff8b,7a,68,fffffff4,7f,0,]
2016-12-09 at 13:33:14 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2f60, negotiated timeout = 60000
2016-12-09 at 13:33:14 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 13:33:14 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2f60 connected
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f60, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,82639,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f60, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,82639,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2f60, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 13:33:14 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=member, startRow=
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,,99999999999999
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,,99999999999999'
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@6c0d9d86
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f60, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,82639,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f60, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,82639,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2f60, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@6c0d9d86; servers = yingji,60020,1481249315144 
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 13:33:14 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 13:33:14 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 41ms
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 6ms
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=1308 associated with replica=0
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 3ms
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=1308 associated with replica=0
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 615 getResultsToAddToCache - number results from RPC: 4,partial != null: false,number of partials so far: 0
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 143 call - Closing scanner id=1308
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 1ms
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 280 nextScanner - Finished {ENCODED => 9a820ae0d288bfb8c904d2deb3149dbb, NAME => 'member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb.', STARTKEY => '', ENDKEY => ''}
2016-12-09 at 13:33:14 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2f60
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2f60
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2f60
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f60, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,82640,0  request:: null response:: null
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2f60 : Unable to read additional data from server sessionid 0x158d73a7f8d2f60, likely server has closed socket
2016-12-09 at 13:33:14 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2f60
2016-12-09 at 13:33:14 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2f60
2016-12-09 at 13:33:14 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2f60 closed
2016-12-09 at 13:33:14 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 13:33:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:43) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:121) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 13:39:19 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 13:39:19 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 13:39:20 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 13:39:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 13:39:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 13:39:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 13:39:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 13:39:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 13:39:20 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 13:39:20 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 13:39:20 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 13:39:20 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:39:20 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 13:39:20 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 13:39:20 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 13:39:20 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,7a,0,0,0,10,6,61,ffffffea,30,fffffffd,5d,ffffffc0,ffffffe4,63,ffffffe5,20,ffffffd9,36,10,27,7d,0,]
2016-12-09 at 13:39:20 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2f7a, negotiated timeout = 60000
2016-12-09 at 13:39:20 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 13:39:20 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2f7a connected
2016-12-09 at 13:39:20 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f7a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,82720,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:39:20 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f7a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,82720,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:39:20 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2f7a, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 13:39:20 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 13:39:20 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f7a, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,82720,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 13:39:20 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f7a, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,82720,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 13:39:20 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2f7a, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 13:39:21 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 13:39:21 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 124ms
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 22ms
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 13:39:21 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 13:39:21 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2f7a
2016-12-09 at 13:39:21 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2f7a
2016-12-09 at 13:39:21 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2f7a
2016-12-09 at 13:39:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f7a, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,82721,0  request:: null response:: null
2016-12-09 at 13:39:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2f7a : Unable to read additional data from server sessionid 0x158d73a7f8d2f7a, likely server has closed socket
2016-12-09 at 13:39:21 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2f7a
2016-12-09 at 13:39:21 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2f7a
2016-12-09 at 13:39:21 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2f7a closed
2016-12-09 at 13:39:21 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:39:21 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:39:21 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 13:39:21 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 13:39:21 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 13:39:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 13:39:21 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,7b,0,0,0,10,19,ffffff82,ffffffe4,30,ffffff9d,ffffffa9,ffffff9f,29,58,28,ffffff88,4,9,ffffff99,3b,4a,0,]
2016-12-09 at 13:39:21 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2f7b, negotiated timeout = 60000
2016-12-09 at 13:39:21 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 13:39:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f7b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,82722,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:39:21 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2f7b connected
2016-12-09 at 13:39:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f7b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,82722,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2f7b, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 13:39:21 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 13:39:21 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 13:39:21 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 13:39:21 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2f7a
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,scutshuxue,99999999999999
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,scutshuxue,99999999999999'
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22
2016-12-09 at 13:39:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f7b, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,82722,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 13:39:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f7b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,82722,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2f7b, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22; servers = yingji,60020,1481249315144 
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 13:39:21 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 13:39:21 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 19ms
2016-12-09 at 13:39:21 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 13:39:22 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 13:39:22 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 16ms
2016-12-09 at 13:39:22 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2f7b
2016-12-09 at 13:39:22 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2f7b
2016-12-09 at 13:39:22 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2f7b
2016-12-09 at 13:39:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2f7b, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,82723,0  request:: null response:: null
2016-12-09 at 13:39:22 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2f7b
2016-12-09 at 13:39:22 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2f7b closed
2016-12-09 at 13:39:22 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 13:39:22 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2f7b
2016-12-09 at 13:39:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2f7b : Unable to read additional data from server sessionid 0x158d73a7f8d2f7b, likely server has closed socket
2016-12-09 at 13:39:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 13:39:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 13:39:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 13:39:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 13:39:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:43) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:121) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 13:54:55 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 13:54:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 13:54:55 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 13:54:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 13:54:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:54:56 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 13:54:56 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 13:54:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 13:54:56 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,ffffffbc,0,0,0,10,25,59,2e,35,ffffffc5,6b,ffffff83,ffffffda,36,3f,1a,50,73,ffffffa6,3b,7c,0,]
2016-12-09 at 13:54:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2fbc, negotiated timeout = 60000
2016-12-09 at 13:54:56 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 13:54:56 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2fbc connected
2016-12-09 at 13:54:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fbc, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,82932,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:54:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fbc, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,82932,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:54:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2fbc, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 13:54:56 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 13:54:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fbc, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,82932,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 13:54:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fbc, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,82932,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2fbc, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 13:54:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 13:54:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 86ms
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 17ms
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 13:54:57 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 13:54:57 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2fbc
2016-12-09 at 13:54:57 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2fbc
2016-12-09 at 13:54:57 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2fbc
2016-12-09 at 13:54:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fbc, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,82933,0  request:: null response:: null
2016-12-09 at 13:54:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2fbc : Unable to read additional data from server sessionid 0x158d73a7f8d2fbc, likely server has closed socket
2016-12-09 at 13:54:57 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2fbc
2016-12-09 at 13:54:57 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2fbc
2016-12-09 at 13:54:57 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2fbc closed
2016-12-09 at 13:54:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:54:57 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 13:54:57 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 13:54:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 13:54:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 13:54:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 13:54:57 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,ffffffbd,0,0,0,10,38,7a,28,35,65,ffffffb7,62,1f,2b,ffffff82,ffffff81,7b,46,2f,50,49,0,]
2016-12-09 at 13:54:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2fbd, negotiated timeout = 60000
2016-12-09 at 13:54:57 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 13:54:57 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 13:54:57 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 13:54:57 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2fbc
2016-12-09 at 13:54:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fbd, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,82934,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:54:57 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2fbd connected
2016-12-09 at 13:54:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fbd, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,82934,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 13:54:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2fbd, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 13:54:57 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=member, startRow=
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,,99999999999999
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,,99999999999999'
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@6c0d9d86
2016-12-09 at 13:54:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fbd, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,82934,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 13:54:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fbd, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,82934,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2fbd, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@6c0d9d86; servers = yingji,60020,1481249315144 
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 13:54:58 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 13:54:58 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 41ms
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 3ms
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=1456 associated with replica=0
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 11ms
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=1456 associated with replica=0
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 615 getResultsToAddToCache - number results from RPC: 4,partial != null: false,number of partials so far: 0
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 143 call - Closing scanner id=1456
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 2ms
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 280 nextScanner - Finished {ENCODED => 9a820ae0d288bfb8c904d2deb3149dbb, NAME => 'member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb.', STARTKEY => '', ENDKEY => ''}
2016-12-09 at 13:54:58 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2fbd
2016-12-09 at 13:54:58 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2fbd
2016-12-09 at 13:54:58 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2fbd
2016-12-09 at 13:54:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fbd, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,82935,0  request:: null response:: null
2016-12-09 at 13:54:58 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2fbd : Unable to read additional data from server sessionid 0x158d73a7f8d2fbd, likely server has closed socket
2016-12-09 at 13:54:58 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2fbd
2016-12-09 at 13:54:58 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2fbd
2016-12-09 at 13:54:58 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2fbd closed
2016-12-09 at 13:54:58 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 13:54:58 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 14:06:38 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:43) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:121) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 14:06:39 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 14:06:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 14:06:40 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 14:06:40 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 14:06:40 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:06:40 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 14:06:40 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 14:06:40 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 14:06:40 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,ffffffea,0,0,0,10,ffffffaa,ffffffe8,7b,33,2,48,f,ffffffc3,19,ffffff9a,fffffff3,ffffffdb,ffffff9f,33,2b,ffffffc4,0,]
2016-12-09 at 14:06:40 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2fea, negotiated timeout = 60000
2016-12-09 at 14:06:40 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 14:06:40 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2fea connected
2016-12-09 at 14:06:40 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fea, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83080,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:06:40 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fea, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83080,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:06:40 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2fea, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 14:06:40 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@c430e6c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 14:06:40 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fea, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,83080,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 14:06:40 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fea, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83080,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 14:06:40 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2fea, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 14:06:41 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 14:06:41 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 14:06:41 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 14:06:41 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 119ms
2016-12-09 at 14:06:41 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 38ms
2016-12-09 at 14:06:41 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 14:06:41 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 14:06:41 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2fea
2016-12-09 at 14:06:41 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2fea
2016-12-09 at 14:06:41 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2fea
2016-12-09 at 14:06:42 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fea, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83081,0  request:: null response:: null
2016-12-09 at 14:06:42 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2fea
2016-12-09 at 14:06:42 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2fea closed
2016-12-09 at 14:06:42 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 14:06:42 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2fea
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x528c868 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:06:42 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x528c868 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:06:42 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x528c8680x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 14:06:42 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 14:06:42 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 14:06:42 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 14:06:42 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 14:06:42 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 14:06:42 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2fea
2016-12-09 at 14:06:42 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,ffffffeb,0,0,0,10,ffffffbe,9,76,33,ffffffa2,ffffff93,ffffffee,7,e,ffffffdd,5a,7,73,ffffffbc,3f,ffffff91,0,]
2016-12-09 at 14:06:42 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2feb, negotiated timeout = 60000
2016-12-09 at 14:06:42 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x528c8680x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 14:06:42 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x528c868-0x158d73a7f8d2feb connected
2016-12-09 at 14:06:42 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2feb, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83082,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:06:42 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2feb, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83082,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x528c868-0x158d73a7f8d2feb, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 14:06:42 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@466276d8, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,scutshuxue,99999999999999
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,scutshuxue,99999999999999'
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@40db2a24
2016-12-09 at 14:06:42 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2feb, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,83082,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 14:06:42 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2feb, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83082,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x528c868-0x158d73a7f8d2feb, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@40db2a24; servers = yingji,60020,1481249315144 
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 14:06:42 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 14:06:42 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 31ms
2016-12-09 at 14:06:42 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 14:06:43 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 14:06:43 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 7ms
2016-12-09 at 14:07:15 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:43) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:121) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 14:07:16 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 14:07:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 14:07:17 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 14:07:17 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 14:07:17 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:07:17 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 14:07:17 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 14:07:17 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 14:07:17 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,fffffff0,0,0,0,10,6,11,fffffffd,33,43,ffffffc8,ffffffde,ffffffd7,6,ffffffd9,13,21,6f,71,67,24,0,]
2016-12-09 at 14:07:17 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2ff0, negotiated timeout = 60000
2016-12-09 at 14:07:17 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 14:07:17 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2ff0 connected
2016-12-09 at 14:07:17 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff0, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83096,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:07:17 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff0, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83096,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:07:17 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2ff0, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 14:07:18 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 14:07:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff0, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,83096,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 14:07:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff0, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83096,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 14:07:18 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2ff0, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 14:07:18 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 14:07:18 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 14:07:18 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 14:07:18 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 104ms
2016-12-09 at 14:07:18 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 35ms
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 14:07:19 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 14:07:19 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2ff0
2016-12-09 at 14:07:19 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2ff0
2016-12-09 at 14:07:19 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2ff0
2016-12-09 at 14:07:19 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff0, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83097,0  request:: null response:: null
2016-12-09 at 14:07:19 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2ff0 : Unable to read additional data from server sessionid 0x158d73a7f8d2ff0, likely server has closed socket
2016-12-09 at 14:07:19 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2ff0
2016-12-09 at 14:07:19 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2ff0
2016-12-09 at 14:07:19 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2ff0 closed
2016-12-09 at 14:07:19 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:07:19 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:07:19 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 14:07:19 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 14:07:19 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 14:07:19 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 14:07:19 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,fffffff1,0,0,0,10,19,32,fffffff7,33,ffffffe3,13,ffffffbe,1c,fffffffb,1b,7b,4c,43,fffffffa,7b,fffffff1,0,]
2016-12-09 at 14:07:19 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2ff1, negotiated timeout = 60000
2016-12-09 at 14:07:19 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 14:07:19 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff1, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83098,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:07:19 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2ff1 connected
2016-12-09 at 14:07:19 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff1, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83098,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2ff1, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 14:07:19 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 14:07:19 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 14:07:19 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 14:07:19 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2ff0
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,scutshuxue,99999999999999
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,scutshuxue,99999999999999'
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22
2016-12-09 at 14:07:19 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff1, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,83098,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 14:07:19 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff1, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83098,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2ff1, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22; servers = yingji,60020,1481249315144 
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 14:07:19 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 14:07:19 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 30ms
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 14:07:19 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 18ms
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:43) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:121) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 14:07:51 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 14:07:51 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 14:07:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 14:07:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 14:07:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 14:07:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 14:07:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 14:07:52 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 14:07:52 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 14:07:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 14:07:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:07:52 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 14:07:52 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 14:07:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 14:07:52 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,fffffff4,0,0,0,10,53,ffffff95,ffffffe5,33,ffffffc3,fffffff6,5b,ffffffeb,ffffffdb,ffffffe4,ffffffb0,ffffffce,ffffffbe,ffffff94,ffffffb9,58,0,]
2016-12-09 at 14:07:52 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2ff4, negotiated timeout = 60000
2016-12-09 at 14:07:52 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 14:07:52 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2ff4 connected
2016-12-09 at 14:07:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff4, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83105,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:07:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff4, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83105,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:07:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2ff4, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 14:07:53 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@c430e6c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 14:07:53 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff4, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,83105,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 14:07:53 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff4, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83105,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 14:07:53 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2ff4, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 14:07:54 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 14:07:54 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 130ms
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 25ms
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 14:07:54 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 14:07:54 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2ff4
2016-12-09 at 14:07:54 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2ff4
2016-12-09 at 14:07:54 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2ff4
2016-12-09 at 14:07:54 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff4, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83106,0  request:: null response:: null
2016-12-09 at 14:07:54 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2ff4 : Unable to read additional data from server sessionid 0x158d73a7f8d2ff4, likely server has closed socket
2016-12-09 at 14:07:54 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2ff4
2016-12-09 at 14:07:54 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2ff4 closed
2016-12-09 at 14:07:54 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 14:07:54 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2ff4
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x528c868 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:07:54 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x528c868 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:07:54 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x528c8680x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 14:07:54 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 14:07:54 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 14:07:54 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 14:07:54 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 14:07:54 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2ff4
2016-12-09 at 14:07:54 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 14:07:54 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,fffffff5,0,0,0,10,66,ffffffb6,ffffffdf,33,63,42,3b,30,ffffffd0,27,18,fffffffa,ffffff92,1d,ffffffce,25,0,]
2016-12-09 at 14:07:54 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2ff5, negotiated timeout = 60000
2016-12-09 at 14:07:54 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x528c8680x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 14:07:54 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x528c868-0x158d73a7f8d2ff5 connected
2016-12-09 at 14:07:54 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff5, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83107,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:07:54 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff5, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83107,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x528c868-0x158d73a7f8d2ff5, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 14:07:54 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@466276d8, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,scutshuxue,99999999999999
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,scutshuxue,99999999999999'
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@40db2a24
2016-12-09 at 14:07:54 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff5, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,83107,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 14:07:54 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff5, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83107,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x528c868-0x158d73a7f8d2ff5, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@40db2a24; servers = yingji,60020,1481249315144 
2016-12-09 at 14:07:54 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 14:07:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 14:07:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 14:07:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 14:07:55 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 14ms
2016-12-09 at 14:07:55 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 14:07:55 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 14:07:55 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 15ms
2016-12-09 at 14:07:55 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2ff5
2016-12-09 at 14:07:55 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2ff5
2016-12-09 at 14:07:55 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2ff5
2016-12-09 at 14:07:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff5, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83108,0  request:: null response:: null
2016-12-09 at 14:07:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2ff5 : Unable to read additional data from server sessionid 0x158d73a7f8d2ff5, likely server has closed socket
2016-12-09 at 14:07:55 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2ff5
2016-12-09 at 14:07:55 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2ff5
2016-12-09 at 14:07:55 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2ff5 closed
2016-12-09 at 14:07:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 14:07:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 14:07:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 14:07:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 14:07:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 14:07:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 14:08:08 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:43) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:121) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 14:08:08 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 14:08:08 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 14:08:08 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 14:08:08 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 14:08:08 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 14:08:08 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 14:08:08 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 14:08:09 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 14:08:09 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 14:08:09 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:08:09 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 14:08:09 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 14:08:09 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 14:08:09 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,fffffff8,0,0,0,10,ffffff9f,19,ffffffce,33,43,25,ffffffd9,fffffffe,ffffffb0,fffffff0,4d,7c,d,ffffffb8,b,ffffff8d,0,]
2016-12-09 at 14:08:09 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2ff8, negotiated timeout = 60000
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 14:08:09 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2ff8 connected
2016-12-09 at 14:08:09 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff8, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83117,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:08:09 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff8, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83117,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:08:09 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2ff8, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 14:08:10 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@c430e6c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 14:08:10 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff8, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,83117,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 14:08:10 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff8, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83117,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 14:08:10 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2ff8, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 14:08:11 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 14:08:11 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 140ms
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 29ms
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 14:08:11 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 14:08:11 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2ff8
2016-12-09 at 14:08:11 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2ff8
2016-12-09 at 14:08:11 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2ff8
2016-12-09 at 14:08:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff8, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83118,0  request:: null response:: null
2016-12-09 at 14:08:11 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2ff8
2016-12-09 at 14:08:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2ff8 : Unable to read additional data from server sessionid 0x158d73a7f8d2ff8, likely server has closed socket
2016-12-09 at 14:08:11 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2ff8
2016-12-09 at 14:08:11 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2ff8 closed
2016-12-09 at 14:08:11 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 14:08:11 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 14:08:11 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 14:08:11 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2ff8
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x528c868 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:08:11 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x528c868 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:08:11 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x528c8680x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 14:08:11 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 14:08:11 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 14:08:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 14:08:11 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,fffffff9,0,0,0,10,ffffffb2,3a,ffffffc8,33,ffffffe3,70,ffffffb8,43,ffffffa5,33,ffffffb5,ffffffa7,ffffffe0,40,20,5a,0,]
2016-12-09 at 14:08:11 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2ff9, negotiated timeout = 60000
2016-12-09 at 14:08:11 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x528c8680x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 14:08:11 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x528c868-0x158d73a7f8d2ff9 connected
2016-12-09 at 14:08:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff9, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83119,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:08:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff9, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83119,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x528c868-0x158d73a7f8d2ff9, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 14:08:11 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@466276d8, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,scutshuxue,99999999999999
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,scutshuxue,99999999999999'
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@40db2a24
2016-12-09 at 14:08:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff9, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,83119,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 14:08:11 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff9, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83119,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x528c868-0x158d73a7f8d2ff9, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@40db2a24; servers = yingji,60020,1481249315144 
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 14:08:11 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 14:08:11 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 38ms
2016-12-09 at 14:08:11 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 14:08:12 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 14:08:12 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 7ms
2016-12-09 at 14:08:12 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2ff9
2016-12-09 at 14:08:12 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2ff9
2016-12-09 at 14:08:12 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2ff9
2016-12-09 at 14:08:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ff9, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83120,0  request:: null response:: null
2016-12-09 at 14:08:12 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2ff9 : Unable to read additional data from server sessionid 0x158d73a7f8d2ff9, likely server has closed socket
2016-12-09 at 14:08:12 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2ff9
2016-12-09 at 14:08:12 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2ff9
2016-12-09 at 14:08:12 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2ff9 closed
2016-12-09 at 14:08:12 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 14:08:12 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 14:08:12 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 14:08:12 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 14:08:12 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 14:08:12 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1363560175) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:43) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:121) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 14:09:04 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 14:09:04 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 14:09:05 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 14:09:05 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 14:09:05 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 14:09:05 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 14:09:05 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 14:09:05 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 14:09:05 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 14:09:05 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 14:09:05 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:09:05 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 14:09:05 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 14:09:05 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 14:09:05 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,fffffffe,0,0,0,10,ffffffc5,5b,ffffffc2,33,ffffff82,ffffffbc,ffffff97,ffffff88,ffffff9a,76,1c,ffffffd3,ffffffb4,ffffffc9,34,27,0,]
2016-12-09 at 14:09:05 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2ffe, negotiated timeout = 60000
2016-12-09 at 14:09:05 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 14:09:05 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d2ffe connected
2016-12-09 at 14:09:05 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ffe, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83135,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:09:05 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ffe, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83135,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:09:05 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2ffe, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 14:09:05 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 14:09:06 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ffe, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,83135,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 14:09:06 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ffe, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83135,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d2ffe, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 14:09:06 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 14:09:06 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 109ms
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 16ms
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 14:09:06 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 14:09:06 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2ffe
2016-12-09 at 14:09:06 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2ffe
2016-12-09 at 14:09:06 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2ffe
2016-12-09 at 14:09:06 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2ffe, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83136,0  request:: null response:: null
2016-12-09 at 14:09:06 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2ffe
2016-12-09 at 14:09:06 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2ffe : Unable to read additional data from server sessionid 0x158d73a7f8d2ffe, likely server has closed socket
2016-12-09 at 14:09:06 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2ffe closed
2016-12-09 at 14:09:06 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 14:09:06 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2ffe
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 14:09:06 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x65a15628 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:09:06 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x65a15628 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 14:09:06 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 14:09:06 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 14:09:06 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 14:09:07 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 14:09:07 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,2f,ffffffff,0,0,0,10,ffffffd8,7c,ffffffbc,33,22,8,77,ffffffcd,ffffff8f,ffffffb9,ffffff83,fffffffe,ffffff87,52,49,fffffff4,0,]
2016-12-09 at 14:09:07 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d2fff, negotiated timeout = 60000
2016-12-09 at 14:09:07 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x65a156280x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 14:09:07 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fff, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83137,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:09:07 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x65a15628-0x158d73a7f8d2fff connected
2016-12-09 at 14:09:07 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fff, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83137,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2fff, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 14:09:07 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e6a5539, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 14:09:07 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 14:09:07 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 14:09:07 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d2ffe
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,scutshuxue,99999999999999
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,scutshuxue,99999999999999'
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22
2016-12-09 at 14:09:07 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fff, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,83137,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 14:09:07 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fff, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83137,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x65a15628-0x158d73a7f8d2fff, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@1fde5d22; servers = yingji,60020,1481249315144 
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 14:09:07 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 14:09:07 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 21ms
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Get, callTime: 8ms
2016-12-09 at 14:09:07 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d2fff
2016-12-09 at 14:09:07 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d2fff
2016-12-09 at 14:09:07 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d2fff
2016-12-09 at 14:09:07 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d2fff, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83138,0  request:: null response:: null
2016-12-09 at 14:09:07 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d2fff : Unable to read additional data from server sessionid 0x158d73a7f8d2fff, likely server has closed socket
2016-12-09 at 14:09:07 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d2fff
2016-12-09 at 14:09:07 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d2fff closed
2016-12-09 at 14:09:07 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d2fff
2016-12-09 at 14:09:07 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 14:09:07 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 15:05:46 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:55) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:133) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 15:05:47 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 15:05:47 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 15:05:47 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 15:05:47 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:05:47 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 15:05:47 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 15:05:47 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 15:05:47 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,30,ffffffe4,0,0,0,10,ffffff9e,78,fffffff3,fffffff2,50,ffffff90,ffffff90,ffffffd1,ffffffbb,ffffff9d,5,fffffff5,ffffffe2,39,ffffffe3,b,0,]
2016-12-09 at 15:05:47 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d30e4, negotiated timeout = 60000
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 15:05:47 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d30e4 connected
2016-12-09 at 15:05:47 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d30e4, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83885,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:05:47 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d30e4, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83885,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:05:47 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d30e4, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 15:05:48 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 15:05:48 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d30e4, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,83885,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 15:05:48 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d30e4, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83885,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 15:05:48 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d30e4, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 15:05:48 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 15:05:48 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 15:05:48 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 15:05:48 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 91ms
2016-12-09 at 15:05:49 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 13ms
2016-12-09 at 15:05:49 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 15:05:49 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 15:05:49 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d30e4
2016-12-09 at 15:05:49 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d30e4
2016-12-09 at 15:05:49 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d30e4
2016-12-09 at 15:05:49 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d30e4, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83886,0  request:: null response:: null
2016-12-09 at 15:05:49 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d30e4 : Unable to read additional data from server sessionid 0x158d73a7f8d30e4, likely server has closed socket
2016-12-09 at 15:05:49 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d30e4
2016-12-09 at 15:05:49 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d30e4
2016-12-09 at 15:05:49 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d30e4 closed
2016-12-09 at 15:05:49 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 15:05:49 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 15:05:49 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 15:05:49 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 15:05:49 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 15:05:49 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 15:05:49 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 15:05:49 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 15:05:49 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x31dadd46 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:05:49 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x31dadd46 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:05:49 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x31dadd460x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 15:05:49 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 15:05:49 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 15:05:49 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 15:05:49 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,30,ffffffe5,0,0,0,10,ffffffb1,ffffff99,ffffffed,fffffff2,fffffff0,ffffffdb,6f,16,ffffffb0,ffffffe0,6c,20,ffffffb6,ffffffc2,fffffff7,ffffffd8,0,]
2016-12-09 at 15:05:49 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d30e5, negotiated timeout = 60000
2016-12-09 at 15:05:49 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x31dadd460x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 15:05:49 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d30e5, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83887,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:05:49 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d30e5, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83887,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:05:49 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x31dadd46-0x158d73a7f8d30e5 connected
2016-12-09 at 15:05:49 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x31dadd46-0x158d73a7f8d30e5, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 15:05:49 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4ed5eb72, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 15:05:49 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 15:05:49 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 15:05:49 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d30e4
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:55) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:133) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 15:13:20 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 15:13:20 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 15:13:21 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 15:13:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 15:13:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 15:13:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 15:13:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 15:13:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 15:13:21 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 15:13:21 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 15:13:21 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 15:13:21 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:13:21 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 15:13:21 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 15:13:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 15:13:21 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,31,6,0,0,0,10,ffffffc1,45,22,fffffff8,19,ffffffcd,6f,4,3c,ffffff81,ffffffdc,ffffffa3,e,6f,ffffffc2,ffffffff,0,]
2016-12-09 at 15:13:21 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d3106, negotiated timeout = 60000
2016-12-09 at 15:13:21 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 15:13:21 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d3106 connected
2016-12-09 at 15:13:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3106, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83993,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:13:21 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3106, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83993,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:13:21 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d3106, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 15:13:21 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3106, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,83993,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3106, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83993,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d3106, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 15:13:22 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 15:13:22 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 67ms
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 11ms
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 15:13:22 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 15:13:22 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d3106
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d3106
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d3106
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3106, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83994,0  request:: null response:: null
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d3106 : Unable to read additional data from server sessionid 0x158d73a7f8d3106, likely server has closed socket
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d3106
2016-12-09 at 15:13:22 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d3106
2016-12-09 at 15:13:22 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d3106 closed
2016-12-09 at 15:13:22 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 15:13:22 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 15:13:22 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 15:13:22 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d3106
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x31dadd46 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:13:22 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x31dadd46 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:13:22 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x31dadd460x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 15:13:22 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 15:13:22 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 15:13:22 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,31,7,0,0,0,10,ffffffd4,66,1c,fffffff8,ffffffb9,18,4f,49,32,ffffffc4,43,ffffffcf,ffffffe2,fffffff7,ffffffd6,ffffffcc,0,]
2016-12-09 at 15:13:22 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d3107, negotiated timeout = 60000
2016-12-09 at 15:13:22 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x31dadd460x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 15:13:22 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x31dadd46-0x158d73a7f8d3107 connected
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3107, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83995,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3107, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83995,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x31dadd46-0x158d73a7f8d3107, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 15:13:22 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4ed5eb72, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,1,99999999999999
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,1,99999999999999'
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@62ef27a8
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3107, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,83995,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 15:13:22 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3107, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83995,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x31dadd46-0x158d73a7f8d3107, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@62ef27a8; servers = yingji,60020,1481249315144 
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 15:13:22 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 15:13:22 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 56ms
2016-12-09 at 15:13:22 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Multi, callTime: 40ms
2016-12-09 at 15:13:23 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d3107
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d3107
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d3107
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3107, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83996,0  request:: null response:: null
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d3107 : Unable to read additional data from server sessionid 0x158d73a7f8d3107, likely server has closed socket
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d3107
2016-12-09 at 15:13:23 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d3107 closed
2016-12-09 at 15:13:23 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 15:13:23 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d3107
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x32f232a5 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:13:23 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x32f232a5 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:13:23 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x32f232a50x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 15:13:23 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 15:13:23 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 15:13:23 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,31,8,0,0,0,10,34,c,ffffffff,fffffff7,ffffffd9,ffffff92,ffffffab,ffffffa1,fffffffc,12,48,ffffffa8,4,ffffffa4,3d,ffffffce,0,]
2016-12-09 at 15:13:23 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d3108, negotiated timeout = 60000
2016-12-09 at 15:13:23 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x32f232a50x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3108, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,83997,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:13:23 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x32f232a5-0x158d73a7f8d3108 connected
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3108, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,83997,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x32f232a5-0x158d73a7f8d3108, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 15:13:23 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@43f82e78, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=member, startRow=
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,,99999999999999
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,,99999999999999'
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@e54303
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3108, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,83997,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 15:13:23 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 15:13:23 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 15:13:23 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d3107
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3108, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,83997,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x32f232a5-0x158d73a7f8d3108, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@e54303; servers = yingji,60020,1481249315144 
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 15:13:23 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 15:13:23 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 15ms
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 6ms
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=2072 associated with replica=0
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 2ms
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=2072 associated with replica=0
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 615 getResultsToAddToCache - number results from RPC: 9,partial != null: false,number of partials so far: 0
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 143 call - Closing scanner id=2072
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 5ms
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 280 nextScanner - Finished {ENCODED => 9a820ae0d288bfb8c904d2deb3149dbb, NAME => 'member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb.', STARTKEY => '', ENDKEY => ''}
2016-12-09 at 15:13:23 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d3108
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d3108
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d3108
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3108, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,83998,0  request:: null response:: null
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d3108 : Unable to read additional data from server sessionid 0x158d73a7f8d3108, likely server has closed socket
2016-12-09 at 15:13:23 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d3108
2016-12-09 at 15:13:23 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d3108 closed
2016-12-09 at 15:13:23 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d3108
2016-12-09 at 15:13:23 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 15:13:23 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:57) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:135) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:30) [bin/:?]

2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 15:15:54 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-09 at 15:15:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-09 at 15:15:55 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 15:15:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 15:15:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7690781 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:15:55 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7690781 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 15:15:55 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 15:15:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 15:15:55 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,31,12,0,0,0,10,43,ffffffb0,ffffff97,fffffff8,ffffff9a,ffffffe4,fffffffd,ffffffa2,14,46,ffffffcb,3f,ffffff86,ffffffbe,27,fffffffa,0,]
2016-12-09 at 15:15:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d3112, negotiated timeout = 60000
2016-12-09 at 15:15:55 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x76907810x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 15:15:55 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7690781-0x158d73a7f8d3112 connected
2016-12-09 at 15:15:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3112, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,84026,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:15:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3112, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,84026,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:15:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d3112, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 15:15:56 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15a34df2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3112, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,84026,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3112, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,84026,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7690781-0x158d73a7f8d3112, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 15:15:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-09 at 15:15:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 59ms
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 10ms
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-09 at 15:15:56 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-09 at 15:15:56 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d3112
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d3112
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d3112
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3112, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,84027,0  request:: null response:: null
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d3112
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d3112 : Unable to read additional data from server sessionid 0x158d73a7f8d3112, likely server has closed socket
2016-12-09 at 15:15:56 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d3112 closed
2016-12-09 at 15:15:56 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d3112
2016-12-09 at 15:15:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x31dadd46 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:15:56 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x31dadd46 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:15:56 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x31dadd460x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 15:15:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 15:15:56 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 15:15:56 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 15:15:56 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d3112
2016-12-09 at 15:15:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 15:15:56 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,31,13,0,0,0,10,56,ffffffd1,ffffff91,fffffff8,3a,30,ffffffdd,ffffffe7,9,ffffff89,32,6b,59,47,3c,ffffffc7,0,]
2016-12-09 at 15:15:56 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d3113, negotiated timeout = 60000
2016-12-09 at 15:15:56 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x31dadd460x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3113, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,84028,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3113, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,84028,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x31dadd460x0, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 15:15:56 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4ed5eb72, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 15:15:56 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x31dadd46-0x158d73a7f8d3113 connected
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,1,99999999999999
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,1,99999999999999'
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@62ef27a8
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3113, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,84028,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 15:15:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3113, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,84028,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x31dadd46-0x158d73a7f8d3113, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@62ef27a8; servers = yingji,60020,1481249315144 
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 15:15:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 15:15:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 19ms
2016-12-09 at 15:15:56 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Multi, callTime: 35ms
2016-12-09 at 15:15:57 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d3113
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d3113
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d3113
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3113, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,84029,0  request:: null response:: null
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d3113 : Unable to read additional data from server sessionid 0x158d73a7f8d3113, likely server has closed socket
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d3113
2016-12-09 at 15:15:57 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d3113 closed
2016-12-09 at 15:15:57 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d3113
2016-12-09 at 15:15:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x32f232a5 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:15:57 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x32f232a5 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-09 at 15:15:57 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x32f232a50x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-09 at 15:15:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-09 at 15:15:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-09 at 15:15:57 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,31,14,0,0,0,10,ffffffb6,76,74,fffffff8,59,ffffffaa,39,40,ffffffd3,ffffffd7,36,44,7b,fffffff3,ffffffa2,ffffffc8,0,]
2016-12-09 at 15:15:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d3114, negotiated timeout = 60000
2016-12-09 at 15:15:57 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x32f232a50x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3114, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,84030,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:15:57 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x32f232a5-0x158d73a7f8d3114 connected
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3114, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,84030,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x32f232a5-0x158d73a7f8d3114, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-09 at 15:15:57 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@43f82e78, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=member, startRow=
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=member,,99999999999999
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'member,,99999999999999'
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@e54303
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3114, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,84030,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3114, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,84030,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x32f232a5-0x158d73a7f8d3114, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@e54303; servers = yingji,60020,1481249315144 
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-09 at 15:15:57 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-09 at 15:15:57 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-09 at 15:15:57 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d3113
2016-12-09 at 15:15:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-09 at 15:15:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 13ms
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb., hostname=yingji,60020,1481249315144, seqNum=16]
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 2ms
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=2096 associated with replica=0
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 5ms
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=2096 associated with replica=0
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 615 getResultsToAddToCache - number results from RPC: 9,partial != null: false,number of partials so far: 0
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 143 call - Closing scanner id=2096
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 1ms
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 280 nextScanner - Finished {ENCODED => 9a820ae0d288bfb8c904d2deb3149dbb, NAME => 'member,,1480735165969.9a820ae0d288bfb8c904d2deb3149dbb.', STARTKEY => '', ENDKEY => ''}
2016-12-09 at 15:15:57 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d3114
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d3114
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d3114
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d3114, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,84031,0  request:: null response:: null
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d3114 : Unable to read additional data from server sessionid 0x158d73a7f8d3114, likely server has closed socket
2016-12-09 at 15:15:57 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d3114
2016-12-09 at 15:15:57 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d3114 closed
2016-12-09 at 15:15:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-09 at 15:15:57 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d3114
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: interrupted while waiting for call responses
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-09 at 15:15:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1732238286) connection to yingji/192.169.77.211:60020 from acer: stopped, connections 0
2016-12-10 at 08:57:54 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:59) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:137) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:31) [bin/:?]

2016-12-10 at 08:57:54 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 08:57:54 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 08:57:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 08:57:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 08:57:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 08:57:54 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 08:57:54 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 08:57:54 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 08:57:55 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 08:57:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 08:57:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7671cb68 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:57:55 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7671cb68 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 08:57:55 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 08:57:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 08:57:55 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,46,0,0,0,10,ffffffa4,68,ffffff95,76,ffffff85,ffffff99,f,29,4c,ffffffd4,2a,ffffff86,71,ffffff88,ffffffa2,ffffff86,0,]
2016-12-10 at 08:57:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d4246, negotiated timeout = 60000
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 08:57:55 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7671cb68-0x158d73a7f8d4246 connected
2016-12-10 at 08:57:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4246, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98235,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:57:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4246, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98235,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:57:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d4246, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 08:57:56 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1807e3f6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 08:57:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4246, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,98235,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-10 at 08:57:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4246, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,98235,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-10 at 08:57:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d4246, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 08:57:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-10 at 08:57:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 177ms
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 16ms
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-10 at 08:57:57 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-10 at 08:57:57 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d4246
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d4246
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d4246
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4246, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,98236,0  request:: null response:: null
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d4246
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d4246 : Unable to read additional data from server sessionid 0x158d73a7f8d4246, likely server has closed socket
2016-12-10 at 08:57:57 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d4246 closed
2016-12-10 at 08:57:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-10 at 08:57:57 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d4246
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0xb7c4869 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:57:57 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0xb7c4869 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:57:57 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 08:57:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 08:57:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 08:57:57 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,47,0,0,0,10,ffffffb7,ffffff89,ffffff8f,76,25,ffffffe5,ffffffee,6d,41,17,ffffff92,ffffffb1,44,11,ffffffb7,53,0,]
2016-12-10 at 08:57:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d4247, negotiated timeout = 60000
2016-12-10 at 08:57:57 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 08:57:57 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0xb7c4869-0x158d73a7f8d4247 connected
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4247, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98237,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4247, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98237,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0xb7c4869-0x158d73a7f8d4247, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 08:57:57 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@740d2e78, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 08:57:57 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-10 at 08:57:57 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-10 at 08:57:57 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d4246
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7e6ef134 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:57:57 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7e6ef134 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:57:57 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 08:57:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 08:57:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 08:57:57 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,48,0,0,0,10,16,2f,72,76,45,5f,4b,ffffffc6,c,66,ffffff96,ffffff8a,67,ffffffbd,1d,55,0,]
2016-12-10 at 08:57:57 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d4248, negotiated timeout = 60000
2016-12-10 at 08:57:57 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4248, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98238,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:57:57 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7e6ef134-0x158d73a7f8d4248 connected
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4248, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98238,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4248, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 08:57:57 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1f010bf0, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=test_table, startRow=
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=test_table,,99999999999999
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'test_table,,99999999999999'
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4248, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,98238,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 08:57:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4248, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,98238,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4248, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 08:57:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 08:57:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 17ms
2016-12-10 at 08:57:57 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-10 at 08:57:58 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 143 call - Closing scanner id=-1
2016-12-10 at 08:58:15 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:59) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:137) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:31) [bin/:?]

2016-12-10 at 08:58:15 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 08:58:15 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 08:58:15 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 08:58:15 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 08:58:15 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 08:58:15 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 08:58:15 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 08:58:15 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 08:58:15 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 08:58:16 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 08:58:16 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 08:58:16 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7671cb68 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:58:16 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7671cb68 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 08:58:16 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 08:58:16 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 08:58:16 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,49,0,0,0,10,29,50,6c,76,ffffffe5,ffffffaa,2a,b,1,ffffffa9,fffffffd,ffffffb5,3a,46,32,22,0,]
2016-12-10 at 08:58:16 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d4249, negotiated timeout = 60000
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 08:58:16 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7671cb68-0x158d73a7f8d4249 connected
2016-12-10 at 08:58:16 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4249, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98239,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:58:16 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4249, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98239,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:58:16 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d4249, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 08:58:17 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1807e3f6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 08:58:17 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4249, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,98239,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-10 at 08:58:17 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4249, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,98239,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-10 at 08:58:17 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d4249, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 08:58:17 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-10 at 08:58:17 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-10 at 08:58:17 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-10 at 08:58:17 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 69ms
2016-12-10 at 08:58:17 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 15ms
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-10 at 08:58:18 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-10 at 08:58:18 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d4249
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d4249
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d4249
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4249, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,98240,0  request:: null response:: null
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d4249 : Unable to read additional data from server sessionid 0x158d73a7f8d4249, likely server has closed socket
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d4249
2016-12-10 at 08:58:18 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d4249
2016-12-10 at 08:58:18 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d4249 closed
2016-12-10 at 08:58:18 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0xb7c4869 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:58:18 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0xb7c4869 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:58:18 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 08:58:18 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-10 at 08:58:18 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-10 at 08:58:18 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d4249
2016-12-10 at 08:58:18 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 08:58:18 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 08:58:18 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,4a,0,0,0,10,fffffff0,ffffffec,7d,76,5,ffffffc8,ffffff8c,3c,21,ffffffe0,ffffffc7,33,ffffffbf,ffffffab,fffffff4,ffffffba,0,]
2016-12-10 at 08:58:18 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d424a, negotiated timeout = 60000
2016-12-10 at 08:58:18 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d424a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98241,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:58:18 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0xb7c4869-0x158d73a7f8d424a connected
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d424a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98241,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0xb7c4869-0x158d73a7f8d424a, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 08:58:18 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@740d2e78, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7e6ef134 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:58:18 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7e6ef134 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 08:58:18 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 08:58:18 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 08:58:18 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 08:58:18 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,4b,0,0,0,10,3,e,78,76,ffffffa5,13,6c,ffffff81,16,23,2f,5f,ffffff93,34,9,ffffff88,0,]
2016-12-10 at 08:58:18 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d424b, negotiated timeout = 60000
2016-12-10 at 08:58:18 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d424b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98242,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:58:18 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7e6ef134-0x158d73a7f8d424b connected
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d424b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98242,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d424b, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 08:58:18 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1f010bf0, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=test_tables, startRow=
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=test_tables,,99999999999999
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'test_tables,,99999999999999'
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d424b, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,98242,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 08:58:18 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d424b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,98242,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d424b, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 08:58:18 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 08:58:18 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 10ms
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=test_tables,,1481286462089.ecfa15f167834c78b46f80dca40c30c9., hostname=yingji,60020,1481249315144, seqNum=2]
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 5ms
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=13081 associated with replica=0
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 49ms
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=13081 associated with replica=0
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 615 getResultsToAddToCache - number results from RPC: 713,partial != null: false,number of partials so far: 0
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 143 call - Closing scanner id=13081
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 1ms
2016-12-10 at 08:58:18 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 280 nextScanner - Finished {ENCODED => ecfa15f167834c78b46f80dca40c30c9, NAME => 'test_tables,,1481286462089.ecfa15f167834c78b46f80dca40c30c9.', STARTKEY => '', ENDKEY => ''}
2016-12-10 at 08:59:59 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:59) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:137) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:31) [bin/:?]

2016-12-10 at 08:59:59 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 08:59:59 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 08:59:59 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 08:59:59 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 08:59:59 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 08:59:59 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 09:00:00 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:00:00 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:00:00 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7671cb68 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:00:00 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7671cb68 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:00:00 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:00:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:00:00 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,5e,0,0,0,10,b,60,ffffffc4,76,ffffff85,3c,15,2,ffffffa2,ffffffbc,fffffff0,2a,ffffffd4,41,fffffffe,1d,0,]
2016-12-10 at 09:00:00 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d425e, negotiated timeout = 60000
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:00:00 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7671cb68-0x158d73a7f8d425e connected
2016-12-10 at 09:00:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d425e, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98293,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:00:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d425e, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98293,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:00:00 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d425e, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:00:01 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1807e3f6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:00:01 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d425e, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,98293,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-10 at 09:00:01 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d425e, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,98293,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-10 at 09:00:01 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d425e, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:00:01 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-10 at 09:00:01 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-10 at 09:00:01 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-10 at 09:00:01 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 71ms
2016-12-10 at 09:00:01 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 13ms
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-10 at 09:00:02 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-10 at 09:00:02 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d425e
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d425e
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d425e
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d425e, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,98294,0  request:: null response:: null
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d425e : Unable to read additional data from server sessionid 0x158d73a7f8d425e, likely server has closed socket
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d425e
2016-12-10 at 09:00:02 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d425e
2016-12-10 at 09:00:02 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d425e closed
2016-12-10 at 09:00:02 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0xb7c4869 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:00:02 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0xb7c4869 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:00:02 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:00:02 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:00:02 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:00:02 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,5f,0,0,0,10,1e,ffffff81,ffffffbe,76,25,ffffff88,fffffff4,46,ffffff98,ffffffff,57,56,ffffffa7,ffffffca,12,ffffffeb,0,]
2016-12-10 at 09:00:02 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d425f, negotiated timeout = 60000
2016-12-10 at 09:00:02 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d425f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98295,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:00:02 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0xb7c4869-0x158d73a7f8d425f connected
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d425f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98295,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0xb7c4869-0x158d73a7f8d425f, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:00:02 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@740d2e78, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7e6ef134 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:00:02 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7e6ef134 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:00:02 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:00:02 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:00:02 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:00:02 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,60,0,0,0,10,ffffffe1,48,ffffffe5,75,44,76,3a,3b,9,ffffffad,44,ffffff9c,3e,ffffff91,a,ffffff8f,0,]
2016-12-10 at 09:00:02 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d4260, negotiated timeout = 60000
2016-12-10 at 09:00:02 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-10 at 09:00:02 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4260, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98296,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:00:02 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d425e
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4260, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98296,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:00:02 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1f010bf0, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:00:02 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:00:02 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7e6ef134-0x158d73a7f8d4260 connected
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=test_tables, startRow=
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=test_tables,,99999999999999
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'test_tables,,99999999999999'
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4260, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,98296,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:00:02 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4260, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,98296,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4260, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 09:00:02 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:00:02 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 31ms
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=test_tables,,1481286462089.ecfa15f167834c78b46f80dca40c30c9., hostname=yingji,60020,1481249315144, seqNum=2]
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 2ms
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=13114 associated with replica=0
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 32ms
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=13114 associated with replica=0
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 615 getResultsToAddToCache - number results from RPC: 1426,partial != null: false,number of partials so far: 0
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 143 call - Closing scanner id=13114
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 3ms
2016-12-10 at 09:00:02 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 280 nextScanner - Finished {ENCODED => ecfa15f167834c78b46f80dca40c30c9, NAME => 'test_tables,,1481286462089.ecfa15f167834c78b46f80dca40c30c9.', STARTKEY => '', ENDKEY => ''}
2016-12-10 at 09:07:58 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:59) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:137) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:31) [bin/:?]

2016-12-10 at 09:07:58 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 09:07:58 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 09:07:58 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 09:07:58 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 09:07:58 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 09:07:58 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 09:07:58 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 09:07:58 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 09:07:58 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 09:07:59 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:07:59 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:07:59 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7671cb68 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:07:59 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7671cb68 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:07:59 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:07:59 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:07:59 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,ffffff8b,0,0,0,10,ffffffb0,3f,ffffffdf,7a,ffffffac,5b,fffffff3,ffffffd9,2a,ffffffeb,ffffffbc,ffffffd1,ffffffda,ffffff95,ffffffa2,ffffffb8,0,]
2016-12-10 at 09:07:59 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d428b, negotiated timeout = 60000
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:07:59 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7671cb68-0x158d73a7f8d428b connected
2016-12-10 at 09:07:59 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d428b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98424,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:07:59 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d428b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98424,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:07:59 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d428b, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:08:00 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1807e3f6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d428b, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,98424,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d428b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,98424,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d428b, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:08:00 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-10 at 09:08:00 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 71ms
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 13ms
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-10 at 09:08:00 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-10 at 09:08:00 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d428b
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d428b
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d428b
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d428b, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,98425,0  request:: null response:: null
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d428b : Unable to read additional data from server sessionid 0x158d73a7f8d428b, likely server has closed socket
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d428b
2016-12-10 at 09:08:00 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d428b closed
2016-12-10 at 09:08:00 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-10 at 09:08:00 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d428b
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0xb7c4869 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:08:00 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0xb7c4869 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:08:00 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:08:00 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:08:00 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:08:00 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,ffffff8c,0,0,0,10,10,ffffffe5,ffffffc1,7a,ffffffcc,ffffffd5,4f,32,fffffff4,39,ffffffc1,ffffffaa,fffffffc,41,9,ffffffba,0,]
2016-12-10 at 09:08:00 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d428c, negotiated timeout = 60000
2016-12-10 at 09:08:00 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d428c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98426,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:08:00 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0xb7c4869-0x158d73a7f8d428c connected
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d428c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98426,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0xb7c4869-0x158d73a7f8d428c, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:08:00 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@740d2e78, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7e6ef134 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:08:00 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7e6ef134 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:08:00 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:08:00 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:08:00 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-10 at 09:08:00 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:08:00 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:08:00 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d428b
2016-12-10 at 09:08:00 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,42,ffffff8d,0,0,0,10,23,6,ffffffbc,7a,6c,21,2f,77,ffffffe9,7c,28,ffffffd6,ffffffd0,ffffffca,1d,ffffff87,0,]
2016-12-10 at 09:08:00 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d428d, negotiated timeout = 60000
2016-12-10 at 09:08:00 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d428d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,98427,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:08:00 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7e6ef134-0x158d73a7f8d428d connected
2016-12-10 at 09:08:00 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d428d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,98427,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:08:00 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d428d, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:08:00 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1f010bf0, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=test_tables, startRow=
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=test_tables,,99999999999999
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'test_tables,,99999999999999'
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:08:01 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d428d, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,98427,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:08:01 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d428d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,98427,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d428d, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 09:08:01 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:08:01 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 11ms
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=test_tables,,1481286462089.ecfa15f167834c78b46f80dca40c30c9., hostname=yingji,60020,1481249315144, seqNum=2]
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 2ms
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=13207 associated with replica=0
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 87ms
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=13207 associated with replica=0
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 615 getResultsToAddToCache - number results from RPC: 5232,partial != null: false,number of partials so far: 0
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 143 call - Closing scanner id=13207
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 2ms
2016-12-10 at 09:08:01 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 280 nextScanner - Finished {ENCODED => ecfa15f167834c78b46f80dca40c30c9, NAME => 'test_tables,,1481286462089.ecfa15f167834c78b46f80dca40c30c9.', STARTKEY => '', ENDKEY => ''}
2016-12-10 at 09:43:50 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:59) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:137) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:31) [bin/:?]

2016-12-10 at 09:43:50 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 09:43:50 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 09:43:50 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 09:43:50 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 09:43:50 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 09:43:50 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 09:43:50 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 09:43:50 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-10 at 09:43:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 09:43:52 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:43:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:43:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7671cb68 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:43:52 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7671cb68 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:43:52 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:43:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:43:52 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,43,6,0,0,0,10,ffffffc4,10,ffffffec,7d,ffffff92,11,fffffff1,11,ffffffc2,21,17,45,ffffffe8,7f,fffffff7,2c,0,]
2016-12-10 at 09:43:52 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d4306, negotiated timeout = 60000
2016-12-10 at 09:43:52 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:43:52 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7671cb68-0x158d73a7f8d4306 connected
2016-12-10 at 09:43:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4306, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,101491,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:43:52 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4306, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,101491,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:43:52 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d4306, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:43:53 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1807e3f6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:43:53 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4306, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,101493,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,31,0,0,0,17,79926} 
2016-12-10 at 09:43:53 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4306, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,101493,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-10 at 09:43:53 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d4306, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:43:54 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-10 at 09:43:54 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-10 at 09:43:54 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-10 at 09:43:54 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 158ms
2016-12-10 at 09:43:54 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 25ms
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-10 at 09:43:55 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-10 at 09:43:55 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d4306
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d4306
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d4306
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4306, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,101496,0  request:: null response:: null
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d4306 : Unable to read additional data from server sessionid 0x158d73a7f8d4306, likely server has closed socket
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d4306
2016-12-10 at 09:43:55 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d4306 closed
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-10 at 09:43:55 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d4306
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-10 at 09:43:55 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-10 at 09:43:55 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-10 at 09:43:55 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d4306
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0xb7c4869 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:43:55 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0xb7c4869 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:43:55 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:43:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:43:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:43:55 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,43,7,0,0,0,10,ffffffd7,31,ffffffe6,7d,32,5d,ffffffd0,56,ffffffb7,64,7e,70,ffffffbb,8,c,fffffffa,0,]
2016-12-10 at 09:43:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d4307, negotiated timeout = 60000
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4307, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,101497,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0xb7c4869-0x158d73a7f8d4307 connected
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4307, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,101497,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0xb7c4869-0x158d73a7f8d4307, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@740d2e78, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7e6ef134 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:43:55 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7e6ef134 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:43:55 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:43:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:43:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:43:55 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,43,8,0,0,0,10,36,ffffffd7,ffffffc8,7d,52,ffffffd7,2c,ffffffaf,ffffff82,ffffffb3,ffffff82,49,ffffffdd,ffffffb4,72,fffffffb,0,]
2016-12-10 at 09:43:55 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d4308, negotiated timeout = 60000
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,101498,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7e6ef134-0x158d73a7f8d4308 connected
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,101498,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4308, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1f010bf0, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=test_tables, startRow=
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=test_tables,,99999999999999
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'test_tables,,99999999999999'
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,101498,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,101498,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4308, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 441 closeConnection - ignored java.net.SocketException: Socket is closed
	at sun.nio.ch.SocketAdaptor.getOutputStream(SocketAdaptor.java:248) ~[?:1.8.0_40]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.closeConnection(RpcClientImpl.java:437) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.handleConnectionFailure(RpcClientImpl.java:485) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:425) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:722) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:906) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:873) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1241) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094) [hbase-protocol-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:201) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:180) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:210) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:364) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:338) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:136) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65) [hbase-client-1.2.3.jar:1.2.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_40]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_40]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]

2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 448 closeConnection - ignored java.net.SocketException: Socket is closed
	at sun.nio.ch.SocketAdaptor.getInputStream(SocketAdaptor.java:226) ~[?:1.8.0_40]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.closeConnection(RpcClientImpl.java:444) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.handleConnectionFailure(RpcClientImpl.java:485) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:425) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:722) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:906) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:873) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1241) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094) [hbase-protocol-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:201) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:180) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:210) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:364) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:338) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:136) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65) [hbase-client-1.2.3.jar:1.2.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_40]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_40]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]

2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: 拒绝连接
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.MetaCache 383 clearCache - Removed region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0 from cache
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 5,8  replyHeader:: 5,101500,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,101500,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4308, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 704 setupIOstreams - Not trying to connect to yingji/192.169.77.211:60020 this server is in the failed servers list
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: This server is in the failed servers list: yingji/192.169.77.211:60020
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.MetaCache 383 clearCache - Removed region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0 from cache
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 7,8  replyHeader:: 7,101500,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:43:55 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 8,4  replyHeader:: 8,101500,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4308, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:43:55 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 704 setupIOstreams - Not trying to connect to yingji/192.169.77.211:60020 this server is in the failed servers list
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: This server is in the failed servers list: yingji/192.169.77.211:60020
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-10 at 09:43:55 CST TRACE org.apache.hadoop.hbase.client.MetaCache 383 clearCache - Removed region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0 from cache
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:43:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 9,8  replyHeader:: 9,101510,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:43:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 10,4  replyHeader:: 10,101510,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4308, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 09:43:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:43:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 704 setupIOstreams - Not trying to connect to yingji/192.169.77.211:60020 this server is in the failed servers list
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: This server is in the failed servers list: yingji/192.169.77.211:60020
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.client.MetaCache 383 clearCache - Removed region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0 from cache
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:43:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 11,8  replyHeader:: 11,101512,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:43:56 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 12,4  replyHeader:: 12,101512,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4308, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 09:43:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:43:56 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 704 setupIOstreams - Not trying to connect to yingji/192.169.77.211:60020 this server is in the failed servers list
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: This server is in the failed servers list: yingji/192.169.77.211:60020
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-10 at 09:43:56 CST TRACE org.apache.hadoop.hbase.client.MetaCache 383 clearCache - Removed region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0 from cache
2016-12-10 at 09:43:57 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:43:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 13,8  replyHeader:: 13,101514,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:43:57 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 14,4  replyHeader:: 14,101514,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 09:43:57 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4308, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:43:57 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 09:43:57 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 09:43:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:43:57 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-10 at 09:43:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 441 closeConnection - ignored java.net.SocketException: Socket is closed
	at sun.nio.ch.SocketAdaptor.getOutputStream(SocketAdaptor.java:248) ~[?:1.8.0_40]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.closeConnection(RpcClientImpl.java:437) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.handleConnectionFailure(RpcClientImpl.java:485) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:425) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:722) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:906) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:873) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1241) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094) [hbase-protocol-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:201) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:180) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:210) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:364) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:338) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:136) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65) [hbase-client-1.2.3.jar:1.2.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_40]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_40]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]

2016-12-10 at 09:43:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 448 closeConnection - ignored java.net.SocketException: Socket is closed
	at sun.nio.ch.SocketAdaptor.getInputStream(SocketAdaptor.java:226) ~[?:1.8.0_40]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.closeConnection(RpcClientImpl.java:444) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.handleConnectionFailure(RpcClientImpl.java:485) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:425) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:722) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:906) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:873) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1241) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094) [hbase-protocol-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:201) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:180) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:210) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:364) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:338) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:136) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65) [hbase-client-1.2.3.jar:1.2.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_40]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_40]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]

2016-12-10 at 09:43:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: 拒绝连接
2016-12-10 at 09:43:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-10 at 09:43:57 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-10 at 09:43:57 CST TRACE org.apache.hadoop.hbase.client.MetaCache 383 clearCache - Removed region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0 from cache
2016-12-10 at 09:43:59 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:43:59 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 15,8  replyHeader:: 15,101518,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:43:59 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 16,4  replyHeader:: 16,101518,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 09:43:59 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4308, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:43:59 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 09:43:59 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 09:43:59 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:43:59 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-10 at 09:43:59 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 441 closeConnection - ignored java.net.SocketException: Socket is closed
	at sun.nio.ch.SocketAdaptor.getOutputStream(SocketAdaptor.java:248) ~[?:1.8.0_40]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.closeConnection(RpcClientImpl.java:437) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.handleConnectionFailure(RpcClientImpl.java:485) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:425) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:722) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:906) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:873) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1241) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094) [hbase-protocol-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:201) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:180) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:210) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:364) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:338) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:136) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65) [hbase-client-1.2.3.jar:1.2.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_40]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_40]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]

2016-12-10 at 09:43:59 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 448 closeConnection - ignored java.net.SocketException: Socket is closed
	at sun.nio.ch.SocketAdaptor.getInputStream(SocketAdaptor.java:226) ~[?:1.8.0_40]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.closeConnection(RpcClientImpl.java:444) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.handleConnectionFailure(RpcClientImpl.java:485) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:425) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:722) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:906) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:873) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1241) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094) [hbase-protocol-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:201) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:180) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:210) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:364) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:338) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:136) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65) [hbase-client-1.2.3.jar:1.2.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_40]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_40]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]

2016-12-10 at 09:43:59 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: 拒绝连接
2016-12-10 at 09:43:59 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-10 at 09:43:59 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-10 at 09:43:59 CST TRACE org.apache.hadoop.hbase.client.MetaCache 383 clearCache - Removed region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0 from cache
2016-12-10 at 09:44:03 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:44:03 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 17,8  replyHeader:: 17,101526,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:44:03 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 18,4  replyHeader:: 18,101526,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 09:44:03 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4308, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:44:03 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 09:44:03 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 09:44:03 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:44:03 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-10 at 09:44:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 441 closeConnection - ignored java.net.SocketException: Socket is closed
	at sun.nio.ch.SocketAdaptor.getOutputStream(SocketAdaptor.java:248) ~[?:1.8.0_40]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.closeConnection(RpcClientImpl.java:437) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.handleConnectionFailure(RpcClientImpl.java:485) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:425) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:722) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:906) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:873) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1241) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094) [hbase-protocol-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:201) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:180) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:210) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:364) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:338) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:136) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65) [hbase-client-1.2.3.jar:1.2.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_40]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_40]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]

2016-12-10 at 09:44:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 448 closeConnection - ignored java.net.SocketException: Socket is closed
	at sun.nio.ch.SocketAdaptor.getInputStream(SocketAdaptor.java:226) ~[?:1.8.0_40]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.closeConnection(RpcClientImpl.java:444) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.handleConnectionFailure(RpcClientImpl.java:485) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:425) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:722) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:906) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:873) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1241) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094) [hbase-protocol-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:201) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:180) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:210) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:364) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:338) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:136) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65) [hbase-client-1.2.3.jar:1.2.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_40]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_40]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]

2016-12-10 at 09:44:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: 拒绝连接
2016-12-10 at 09:44:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-10 at 09:44:03 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-10 at 09:44:03 CST TRACE org.apache.hadoop.hbase.client.MetaCache 383 clearCache - Removed region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0 from cache
2016-12-10 at 09:44:13 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:44:13 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 19,8  replyHeader:: 19,101546,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:44:13 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 742 readResponse - Got ping response for sessionid: 0x158d73a7f8d4308 after 8ms
2016-12-10 at 09:44:14 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4308, packet:: clientPath:null serverPath:null finished:false header:: 20,4  replyHeader:: 20,101546,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a36303032308ffffffbeffffffcf48ffffff8c37ffffffc6ffffff9250425546a13a679696e676a6910fffffff4ffffffd4318ffffffc8ffffffb2ffffffdbffffff8affffff8e2b100183,s{79926,79926,1481249330306,1481249330306,0,0,0,0,60,0,79926} 
2016-12-10 at 09:44:14 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4308, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:44:14 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481249315144 
2016-12-10 at 09:44:14 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0]
2016-12-10 at 09:44:14 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:44:14 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-10 at 09:44:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 441 closeConnection - ignored java.net.SocketException: Socket is closed
	at sun.nio.ch.SocketAdaptor.getOutputStream(SocketAdaptor.java:248) ~[?:1.8.0_40]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.closeConnection(RpcClientImpl.java:437) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.handleConnectionFailure(RpcClientImpl.java:485) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:425) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:722) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:906) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:873) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1241) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094) [hbase-protocol-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:201) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:180) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:210) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:364) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:338) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:136) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65) [hbase-client-1.2.3.jar:1.2.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_40]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_40]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]

2016-12-10 at 09:44:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 448 closeConnection - ignored java.net.SocketException: Socket is closed
	at sun.nio.ch.SocketAdaptor.getInputStream(SocketAdaptor.java:226) ~[?:1.8.0_40]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.closeConnection(RpcClientImpl.java:444) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.handleConnectionFailure(RpcClientImpl.java:485) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:425) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:722) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:906) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:873) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1241) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:34094) [hbase-protocol-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:201) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ClientSmallScanner$SmallScannerCallable.call(ClientSmallScanner.java:180) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:210) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:364) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:338) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:136) [hbase-client-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65) [hbase-client-1.2.3.jar:1.2.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_40]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_40]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]

2016-12-10 at 09:44:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: marking at should close, reason: 拒绝连接
2016-12-10 at 09:44:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: closing ipc connection to yingji/192.169.77.211:60020
2016-12-10 at 09:44:14 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: ipc connection to yingji/192.169.77.211:60020 closed
2016-12-10 at 09:44:14 CST TRACE org.apache.hadoop.hbase.client.MetaCache 383 clearCache - Removed region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481249315144, seqNum=0 from cache
2016-12-10 at 09:44:15 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 742 readResponse - Got ping response for sessionid: 0x158d73a7f8d4307 after 1ms
2016-12-10 at 09:45:29 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1437) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.hbase.HBaseConfiguration.checkDefaultsVersion(HBaseConfiguration.java:67) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.addHbaseResources(HBaseConfiguration.java:81) [hbase-common-1.2.3.jar:1.2.3]
	at org.apache.hadoop.hbase.HBaseConfiguration.create(HBaseConfiguration.java:96) [hbase-common-1.2.3.jar:1.2.3]
	at hbase.com.cn.Query.init(Query.java:59) [bin/:?]
	at hbase.com.cn.Query.listTables(Query.java:137) [bin/:?]
	at hbase.com.cn.Query.main(Query.java:31) [bin/:?]

2016-12-10 at 09:45:29 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 09:45:29 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 09:45:29 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 09:45:29 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 09:45:29 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 09:45:29 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 09:45:30 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:45:30 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:45:30 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7671cb68 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:45:30 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7671cb68 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:host.name=master
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.version=1.8.0_40
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.vendor=Oracle Corporation
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.home=/usr/local/jdk1.8.0_40/jre
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.class.path=/home/acer/Develop/EclipseWS/HBase/bin:/home/acer/Develop/EclipseWS/HBase/lib/commons-cli-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-codec-1.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-collections-3.2.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-configuration-1.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-lang-2.6.jar:/home/acer/Develop/EclipseWS/HBase/lib/commons-logging-1.2.jar:/home/acer/Develop/EclipseWS/HBase/lib/guava-12.0.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-annotations-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-auth-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common-2.7.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-client-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-common-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-hadoop-compat-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-procedure-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-protocol-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-server-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/hbase-thrift-1.2.3.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-core-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-jaxrs-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-mapper-asl-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/jackson-xc-1.9.13.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-1.2-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-api-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-core-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-slf4j-impl-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/log4j-web-2.4.1.jar:/home/acer/Develop/EclipseWS/HBase/lib/metrics-core-2.2.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/netty-all-4.0.23.Final.jar:/home/acer/Develop/EclipseWS/HBase/lib/protobuf-java-2.5.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-api-1.7.7.jar:/home/acer/Develop/EclipseWS/HBase/lib/slf4j-log4j12-1.7.5.jar:/home/acer/Develop/EclipseWS/HBase/lib/zookeeper-3.4.9.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-common.jar:/home/acer/Develop/EclipseWS/HBase/lib/hadoop-hdfs-2.6.0-cdh5.7.0.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core-3.1.0-incubating.jar:/home/acer/Develop/EclipseWS/HBase/lib/htrace-core4-4.0.1-incubating.jar
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.io.tmpdir=/tmp
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:java.compiler=<NA>
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.name=Linux
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.arch=amd64
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:os.version=4.4.0-53-generic
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.name=acer
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.home=/home/acer
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.Environment 100 logEnv - Client environment:user.dir=/home/acer/Develop/EclipseWS/HBase
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:45:30 CST DEBUG org.apache.zookeeper.ClientCnxn 117 <clinit> - zookeeper.disableAutoWatchReset is false
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:45:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:45:30 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,43,13,0,0,0,10,59,ffffff9c,5b,7e,ffffffb3,74,5e,fffffff5,ffffff8f,29,6d,c,33,58,71,fffffff4,0,]
2016-12-10 at 09:45:30 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d4313, negotiated timeout = 60000
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7671cb680x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:45:30 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7671cb68-0x158d73a7f8d4313 connected
2016-12-10 at 09:45:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4313, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,101662,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:45:30 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4313, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,101662,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:45:30 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d4313, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:45:31 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1807e3f6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:45:31 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4313, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,101662,0  request:: '/hbase,F  response:: s{698,698,1480733749054,1480733749054,0,33,0,0,0,17,101611} 
2016-12-10 at 09:45:31 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4313, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,101662,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3630303030ffffffb527ffffffc3ffffffedffffffceffffff87ffffffe9ffffffcc50425546a13a679696e676a6910ffffffe0ffffffd4318ffffffbbffffffacffffffdbffffff8affffff8e2b10018ffffffeaffffffd43,s{79896,79896,1481249320583,1481249320583,0,0,0,97064038236498955,56,0,79896} 
2016-12-10 at 09:45:31 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7671cb68-0x158d73a7f8d4313, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 31 byte(s) of data from znode /hbase/master; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:45:31 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service MasterService, sasl=false
2016-12-10 at 09:45:31 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60000
2016-12-10 at 09:45:31 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: starting, connections 1
2016-12-10 at 09:45:31 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: IsMasterRunning, callTime: 68ms
2016-12-10 at 09:45:31 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: GetTableDescriptors, callTime: 12ms
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder 93 getBestComparer - Unsafe comparer selected for byte unaligned system architecture
2016-12-10 at 09:45:32 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 2139 closeMasterService - Closing master protocol: MasterService
2016-12-10 at 09:45:32 CST INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation 1710 closeZooKeeperWatcher - Closing zookeeper sessionid=0x158d73a7f8d4313
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ZooKeeper 673 close - Closing session: 0x158d73a7f8d4313
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn 1370 close - Closing client for session: 0x158d73a7f8d4313
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4313, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,101663,0  request:: null response:: null
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn 1354 disconnect - Disconnecting client for session: 0x158d73a7f8d4313
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 1146 run - An exception was thrown while closing send thread for session 0x158d73a7f8d4313 : Unable to read additional data from server sessionid 0x158d73a7f8d4313, likely server has closed socket
2016-12-10 at 09:45:32 CST INFO  org.apache.zookeeper.ZooKeeper 684 close - Session: 0x158d73a7f8d4313 closed
2016-12-10 at 09:45:32 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl 1157 close - Stopping rpc client
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 570 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: interrupted while waiting for call responses
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 1060 markClosed - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: marking at should close, reason: Origin: InterruptedException
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 860 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: closing ipc connection to yingji/192.169.77.211:60000
2016-12-10 at 09:45:32 CST INFO  org.apache.zookeeper.ClientCnxn$EventThread 519 run - EventThread shut down for session: 0x158d73a7f8d4313
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 866 close - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: ipc connection to yingji/192.169.77.211:60000 closed
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 583 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60000 from acer: stopped, connections 0
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0xb7c4869 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:45:32 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0xb7c4869 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:45:32 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:45:32 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:45:32 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:45:32 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,43,14,0,0,0,10,ffffffb8,41,3e,7e,ffffffd2,ffffffee,ffffffba,4d,59,78,71,ffffffe5,55,4,ffffffd8,fffffff5,0,]
2016-12-10 at 09:45:32 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d4314, negotiated timeout = 60000
2016-12-10 at 09:45:32 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0xb7c48690x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:45:32 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0xb7c4869-0x158d73a7f8d4314 connected
2016-12-10 at 09:45:32 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 243 close - Doing client selector close
2016-12-10 at 09:45:32 CST TRACE org.apache.zookeeper.ClientCnxnSocketNIO 247 close - Closed client selector
2016-12-10 at 09:45:32 CST TRACE org.apache.zookeeper.server.ZooTrace 71 logTraceMessage - SendThread exited loop for session: 0x158d73a7f8d4313
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4314, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,101664,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4314, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,101664,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0xb7c4869-0x158d73a7f8d4314, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:45:32 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@740d2e78, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.client.RetryingCallerInterceptorFactory 79 build - Using NoOpRetryableCallerInterceptor for intercepting the RpcRetryingCaller
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKConfig 105 makeZKPropsFromZooCfg - Skipped reading ZK properties file 'zoo.cfg' since 'hbase.config.read.zookeeper.config' was not set to true
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 130 connect - hconnection-0x7e6ef134 opening connection to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:45:32 CST INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper 120 <init> - Process identifier=hconnection-0x7e6ef134 connecting to ZooKeeper ensemble=192.169.77.211:2181
2016-12-10 at 09:45:32 CST INFO  org.apache.zookeeper.ZooKeeper 438 <init> - Initiating client connection, connectString=192.169.77.211:2181 sessionTimeout=90000 watcher=hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase
2016-12-10 at 09:45:32 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1032 logStartConnect - Opening socket connection to server 192.169.77.211/192.169.77.211:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 at 09:45:32 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 876 primeConnection - Socket connection established to 192.169.77.211/192.169.77.211:2181, initiating session
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 949 primeConnection - Session establishment request sent on 192.169.77.211/192.169.77.211:2181
2016-12-10 at 09:45:32 CST TRACE org.apache.zookeeper.ClientCnxnSocket 124 readConnectResult - readConnectResult 37 0x[0,0,0,0,0,0,ffffffea,60,1,58,ffffffd7,3a,7f,ffffff8d,43,15,0,0,0,10,ffffffcc,62,38,7e,72,3a,ffffff9a,ffffff92,4e,ffffffbb,ffffffd8,10,28,ffffff8d,ffffffec,ffffffc2,0,]
2016-12-10 at 09:45:32 CST INFO  org.apache.zookeeper.ClientCnxn$SendThread 1299 onConnected - Session establishment complete on server 192.169.77.211/192.169.77.211:2181, sessionid = 0x158d73a7f8d4315, negotiated timeout = 60000
2016-12-10 at 09:45:32 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 602 process - hconnection-0x7e6ef1340x0, quorum=192.169.77.211:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2016-12-10 at 09:45:32 CST DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher 686 connectionEvent - hconnection-0x7e6ef134-0x158d73a7f8d4315 connected
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4315, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,101665,0  request:: '/hbase/hbaseid,F  response:: s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4315, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,101665,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a36303030301c30ffffffc8ffffffeb424e65ffffff8150425546a2431656431616335302d383336362d346465612d626233622d343934376634386663393931,s{712,79911,1480733758386,1481249321868,3,0,0,0,67,0,712} 
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4315, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 42 byte(s) of data from znode /hbase/hbaseid; data=PBUF\x0A$1ed1ac50-8366-4dea-b...
2016-12-10 at 09:45:32 CST DEBUG org.apache.hadoop.hbase.ipc.AbstractRpcClient 116 <init> - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1f010bf0, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=test_tables, startRow=
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 122 <init> - Scan table=hbase:meta, startRow=test_tables,,99999999999999
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.client.ClientSmallReversedScanner 164 nextScanner - Advancing internal small scanner to startKey at 'test_tables,,99999999999999'
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 59 getMetaRegionLocation - Looking up meta region location in ZK, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4315, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,101665,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'unassigned,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
2016-12-10 at 09:45:32 CST DEBUG org.apache.zookeeper.ClientCnxn$SendThread 843 readResponse - Reading reply sessionid:0x158d73a7f8d4315, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,101665,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a363030323079ffffffec41ffffffbd2320ffffffb75950425546a13a679696e676a6910fffffff4ffffffd4318ffffffa1ffffff92ffffff9bffffffb3ffffff8e2b100183,s{101611,101611,1481334253722,1481334253722,0,0,0,0,60,0,101611} 
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.zookeeper.ZKUtil 1935 logRetrievedMsg - hconnection-0x7e6ef134-0x158d73a7f8d4315, quorum=192.169.77.211:2181, baseZNode=/hbase Retrieved 29 byte(s) of data from znode /hbase/meta-region-server; data=PBUF\x0A\x13\x0A\x06yingji\x1...
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.client.ZooKeeperRegistry 73 getMetaRegionLocation - Looked up meta region location, connection=org.apache.hadoop.hbase.client.ZooKeeperRegistry@47f9738; servers = yingji,60020,1481334245665 
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=hbase:meta,,1.1588230740, hostname=yingji,60020,1481334245665, seqNum=0]
2016-12-10 at 09:45:32 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 351 <init> - Use SIMPLE authentication for service ClientService, sasl=false
2016-12-10 at 09:45:32 CST DEBUG org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 716 setupIOstreams - Connecting to yingji/192.169.77.211:60020
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection 561 run - IPC Client (1896232624) connection to yingji/192.169.77.211:60020 from acer: starting, connections 1
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 50ms
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=-1 associated with replica=0
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.client.MetaCache 175 cacheLocation - Merged cached locations: [region=test_tables,,1481286462089.ecfa15f167834c78b46f80dca40c30c9., hostname=yingji,60020,1481334245665, seqNum=252]
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 9ms
2016-12-10 at 09:45:32 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=13 associated with replica=0
2016-12-10 at 09:45:33 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 399ms
2016-12-10 at 09:45:33 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 234 updateCurrentlyServingReplica - Setting current scanner as id=13 associated with replica=0
2016-12-10 at 09:45:33 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 615 getResultsToAddToCache - number results from RPC: 5817,partial != null: false,number of partials so far: 0
2016-12-10 at 09:45:33 CST TRACE org.apache.hadoop.hbase.client.ScannerCallableWithReplicas 143 call - Closing scanner id=13
2016-12-10 at 09:45:33 CST TRACE org.apache.hadoop.hbase.ipc.AbstractRpcClient 236 callBlockingMethod - Call: Scan, callTime: 2ms
2016-12-10 at 09:45:33 CST TRACE org.apache.hadoop.hbase.client.ClientScanner 280 nextScanner - Finished {ENCODED => ecfa15f167834c78b46f80dca40c30c9, NAME => 'test_tables,,1481286462089.ecfa15f167834c78b46f80dca40c30c9.', STARTKEY => '', ENDKEY => ''}
2016-12-10 at 11:59:44 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 11:59:44 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 11:59:45 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-10 at 11:59:45 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 12:03:38 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 12:03:38 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 12:03:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-10 at 12:03:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-10 at 12:03:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-10 at 12:03:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 12:03:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-10 at 12:03:39 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2806) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.1.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.1.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 13:34:04 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-10 at 13:34:04 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 13:34:35 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 13:34:35 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 13:34:35 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 13:34:35 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 13:34:35 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 13:34:35 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 13:34:36 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-10 at 13:34:36 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 13:34:58 CST DEBUG org.apache.hadoop.util.Shell 321 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668) [hadoop-common-2.7.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371) [hadoop-common-2.7.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.util.Shell 397 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 232 register - UgiMetrics, User and group related metrics
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.security.Groups 301 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 13:34:59 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.security.Groups 112 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 221 login - hadoop login
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 156 commit - hadoop login commit
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 186 commit - using local user:UnixPrincipal: acer
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 192 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 202 commit - User entry: "acer"
2016-12-10 at 13:34:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation 826 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:22:07 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:22:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:23:17 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:23:17 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:23:17 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:23:17 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:23:17 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:23:17 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:23:18 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:23:18 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:23:18 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:23:18 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:23:18 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:23:18 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:23:18 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:26:34 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:26:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:26:35 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:26:35 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:26:35 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:26:35 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:26:35 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:26:35 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:26:35 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:26:35 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:26:35 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:26:35 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:26:35 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 14:26:35 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:26:35 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:26:35 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:26:35 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 14:26:36 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:26:36 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:26:36 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:26:36 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:27:28 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:27:28 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:27:29 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:27:29 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:27:29 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:27:29 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:27:29 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@1a942c18
2016-12-10 at 14:27:29 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@173ed316
2016-12-10 at 14:27:30 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:27:30 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:27:30 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 14:27:30 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@173ed316
2016-12-10 at 14:27:30 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@173ed316
2016-12-10 at 14:27:30 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@173ed316
2016-12-10 at 14:27:30 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:27:51 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:27:51 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:27:52 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:27:52 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:27:52 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:27:52 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:27:52 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:27:52 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:27:52 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:27:52 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:27:52 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:27:52 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:27:52 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@71ba6d4e
2016-12-10 at 14:27:52 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@74ea2410
2016-12-10 at 14:27:53 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:27:53 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:27:53 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 14:27:53 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@74ea2410
2016-12-10 at 14:27:53 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@74ea2410
2016-12-10 at 14:27:53 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@74ea2410
2016-12-10 at 14:27:53 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:37:01 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:37:01 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:37:02 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:37:02 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:37:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:37:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:37:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:37:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:37:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:37:02 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:38:47 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:38:47 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:38:48 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:38:48 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:38:48 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:38:48 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:38:48 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:38:48 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:38:48 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:38:48 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:38:48 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:38:48 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:38:48 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@d86a6f
2016-12-10 at 14:38:48 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@248e319b
2016-12-10 at 14:38:49 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:38:49 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:38:49 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 14:38:49 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@248e319b
2016-12-10 at 14:38:49 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@248e319b
2016-12-10 at 14:38:49 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@248e319b
2016-12-10 at 14:38:49 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:39:17 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:39:17 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:39:17 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:39:17 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:39:17 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:39:17 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@20140db9
2016-12-10 at 14:39:17 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@470734c3
2016-12-10 at 14:39:18 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:39:18 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:39:18 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 14:39:18 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@470734c3
2016-12-10 at 14:39:18 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@470734c3
2016-12-10 at 14:39:18 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@470734c3
2016-12-10 at 14:39:18 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:40:21 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:40:21 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:40:21 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:40:21 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:40:22 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:40:22 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:41:09 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:41:09 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:41:09 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:41:09 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:41:09 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:41:09 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:41:09 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:41:10 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:41:10 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@20140db9
2016-12-10 at 14:41:10 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@470734c3
2016-12-10 at 14:41:10 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:41:11 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:41:11 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 14:41:11 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@470734c3
2016-12-10 at 14:41:11 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@470734c3
2016-12-10 at 14:41:11 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@470734c3
2016-12-10 at 14:41:11 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:43:24 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:43:24 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:43:25 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:43:25 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:43:25 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:43:25 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:43:25 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 14:43:25 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 14:43:26 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: create {src: "/sdzw/hello.txt" masked { perm: 420 } clientName: "DFSClient_NONMAPREDUCE_307070208_1" createFlag: 3 createParent: true replication: 3 blockSize: 134217728 cryptoProtocolVersion: ENCRYPTION_ZONES}
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: create took 446ms
2016-12-10 at 14:43:26 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: create {fs { fileType: IS_FILE path: "" length: 0 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481352176408 access_time: 1481352176408 block_replication: 3 blocksize: 134217728 fileId: 77936 childrenNum: 0 storagePolicy: 0 }}
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hello.txt, chunkSize=516, chunksPerPacket=127, packetSize=65532
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_307070208_1] with renew id 1 started
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2070 writeChunk - DFSClient writeChunk allocating new packet seqno=0, src=/sdzw/hello.txt, packetSize=65532, chunksPerPacket=127, bytesCurBlock=0
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 666 run - Allocating new block
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 1
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 1
2016-12-10 at 14:43:26 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: addBlock {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_307070208_1" fileId: 77936}
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: addBlock took 31ms
2016-12-10 at 14:43:26 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: addBlock {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750882 generationStamp: 10062 numBytes: 0 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791293952 remaining: 886263267494 blockPoolUsed: 791293952 lastUpdate: 1481352176202 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1545 createBlockOutputStream - pipeline = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1777 createSocketForPipeline - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 14:43:26 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1786 createSocketForPipeline - Send buf size 131072
2016-12-10 at 14:43:26 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #2
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #2
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 3ms
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750882
      generationStamp: 10062
      numBytes: 134217728
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_307070208_1"
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 1
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false

2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750882_10062 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 10
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 0 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750882_10062 sending packet packet seqno: 1 offsetInBlock: 10 lastPacketInBlock: true lastByteOffsetInBlock: 10
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 1 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 587 endBlock - Closing old block BP-410674713-192.169.77.211-1480733607425:blk_1073750882_10062
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: complete {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_307070208_1" last { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750882 generationStamp: 10062 numBytes: 10 } fileId: 77936}
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #3
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #3
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: complete took 11ms
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: complete {result: true}
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getBlockLocations {src: "/sdzw/hello.txt" offset: 0 length: 1342177280}
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #4
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #4
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getBlockLocations took 31ms
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getBlockLocations {locations { fileLength: 10 blocks { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750882 generationStamp: 10062 numBytes: 10 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791293952 remaining: 886263267494 blockPoolUsed: 791293952 lastUpdate: 1481352176202 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } underConstruction: false lastBlock { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750882 generationStamp: 10062 numBytes: 10 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791293952 remaining: 886263267494 blockPoolUsed: 791293952 lastUpdate: 1481352176202 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } isLastBlockComplete: true }}
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 307 fetchLocatedBlocksAndGetLastBlockLength - newInfo = LocatedBlocks{
  fileLength=10
  underConstruction=false
  blocks=[LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750882_10062; getBlockSize()=10; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750882_10062; getBlockSize()=10; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}
  isLastBlockComplete=true}
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 1073 getBestNodeDNAddrPair - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 745 getRemoteBlockReaderFromTcp - BlockReaderFactory(fileName=/sdzw/hello.txt, block=BP-410674713-192.169.77.211-1480733607425:blk_1073750882_10062): trying to create a remote block reader from a TCP socket
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #5
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #5
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 6ms
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 841 nextTcpPeer - nextTcpPeer: created newConnectedPeer NioInetPeer(Socket[addr=/192.169.77.211,port=50010,localport=52478])
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpReadBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750882
      generationStamp: 10062
      numBytes: 10
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-198188927_1"
}
offset: 0
len: 10
sendChecksums: true
cachingStrategy {
}

2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.hdfs.DFSClient 1115 isLocalAddress - Address /192.169.77.211:50010 is not local
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 145 read - Starting read #125ba45e-9586-4443-968e-4ae50c3883d7 file /sdzw/hello.txt from datanode yingji
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 14 headerLen = 25
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 214 readNextPacket - DFSClient readNextPacket got header PacketHeader with packetLen=14 header data: offsetInBlock: 0
seqno: 0
lastPacketInBlock: false
dataLen: 10

2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 285 readTrailingEmptyPacket - Reading empty packet at end of read
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 0 headerLen = 25
2016-12-10 at 14:43:27 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 163 read - Finishing read #125ba45e-9586-4443-968e-4ae50c3883d7
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 14:43:27 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:45:39 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:45:39 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:45:40 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:45:40 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:45:40 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:45:40 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:45:40 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 14:45:40 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:45:41 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:45:41 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:45:41 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: create {src: "/sdzw/hello.txt" masked { perm: 420 } clientName: "DFSClient_NONMAPREDUCE_874948018_1" createFlag: 3 createParent: true replication: 3 blockSize: 134217728 cryptoProtocolVersion: ENCRYPTION_ZONES}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: create took 338ms
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: create {fs { fileType: IS_FILE path: "" length: 0 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481352311696 access_time: 1481352311696 block_replication: 3 blocksize: 134217728 fileId: 77959 childrenNum: 0 storagePolicy: 0 }}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hello.txt, chunkSize=516, chunksPerPacket=127, packetSize=65532
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2070 writeChunk - DFSClient writeChunk allocating new packet seqno=0, src=/sdzw/hello.txt, packetSize=65532, chunksPerPacket=127, bytesCurBlock=0
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_874948018_1] with renew id 1 started
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 666 run - Allocating new block
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 1
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 1
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: addBlock {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_874948018_1" fileId: 77959}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: addBlock took 10ms
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: addBlock {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750885 generationStamp: 10065 numBytes: 0 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791293973 remaining: 886263259302 blockPoolUsed: 791293973 lastUpdate: 1481352311234 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1545 createBlockOutputStream - pipeline = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1777 createSocketForPipeline - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1786 createSocketForPipeline - Send buf size 131072
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #2
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #2
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 3ms
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750885
      generationStamp: 10065
      numBytes: 134217728
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_874948018_1"
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 1
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false

2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750885_10065 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 10
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 0 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750885_10065 sending packet packet seqno: 1 offsetInBlock: 10 lastPacketInBlock: true lastByteOffsetInBlock: 10
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 1 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 587 endBlock - Closing old block BP-410674713-192.169.77.211-1480733607425:blk_1073750885_10065
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: complete {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_874948018_1" last { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750885 generationStamp: 10065 numBytes: 10 } fileId: 77959}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #3
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #3
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: complete took 7ms
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: complete {result: true}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getBlockLocations {src: "/sdzw/hello.txt" offset: 0 length: 1342177280}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #4
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #4
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getBlockLocations took 59ms
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getBlockLocations {locations { fileLength: 10 blocks { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750885 generationStamp: 10065 numBytes: 10 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791293973 remaining: 886263259302 blockPoolUsed: 791293973 lastUpdate: 1481352311234 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } underConstruction: false lastBlock { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750885 generationStamp: 10065 numBytes: 10 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791293973 remaining: 886263259302 blockPoolUsed: 791293973 lastUpdate: 1481352311234 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } isLastBlockComplete: true }}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 307 fetchLocatedBlocksAndGetLastBlockLength - newInfo = LocatedBlocks{
  fileLength=10
  underConstruction=false
  blocks=[LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750885_10065; getBlockSize()=10; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750885_10065; getBlockSize()=10; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}
  isLastBlockComplete=true}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 1073 getBestNodeDNAddrPair - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 745 getRemoteBlockReaderFromTcp - BlockReaderFactory(fileName=/sdzw/hello.txt, block=BP-410674713-192.169.77.211-1480733607425:blk_1073750885_10065): trying to create a remote block reader from a TCP socket
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #5
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #5
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 9ms
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 841 nextTcpPeer - nextTcpPeer: created newConnectedPeer NioInetPeer(Socket[addr=/192.169.77.211,port=50010,localport=52486])
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpReadBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750885
      generationStamp: 10065
      numBytes: 10
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-999767407_1"
}
offset: 0
len: 10
sendChecksums: true
cachingStrategy {
}

2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.hdfs.DFSClient 1115 isLocalAddress - Address /192.169.77.211:50010 is not local
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 145 read - Starting read #33d8b215-3694-44cc-a404-19c30cf2a441 file /sdzw/hello.txt from datanode yingji
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 14 headerLen = 25
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 214 readNextPacket - DFSClient readNextPacket got header PacketHeader with packetLen=14 header data: offsetInBlock: 0
seqno: 0
lastPacketInBlock: false
dataLen: 10

2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 285 readTrailingEmptyPacket - Reading empty packet at end of read
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 0 headerLen = 25
2016-12-10 at 14:45:42 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 163 read - Finishing read #33d8b215-3694-44cc-a404-19c30cf2a441
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 14:45:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 14:46:05 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:46:06 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:46:06 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:46:07 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:46:07 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:46:07 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:46:07 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:46:07 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:46:07 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:46:07 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:46:07 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:46:07 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:46:07 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:46:07 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 14:46:07 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:46:08 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:46:08 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:46:08 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: create {src: "/sdzw/hello.txt" masked { perm: 420 } clientName: "DFSClient_NONMAPREDUCE_1605974099_1" createFlag: 3 createParent: true replication: 3 blockSize: 134217728 cryptoProtocolVersion: ENCRYPTION_ZONES}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: create took 575ms
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: create {fs { fileType: IS_FILE path: "" length: 0 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481352338722 access_time: 1481352338722 block_replication: 3 blocksize: 134217728 fileId: 77963 childrenNum: 0 storagePolicy: 0 }}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hello.txt, chunkSize=516, chunksPerPacket=127, packetSize=65532
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1605974099_1] with renew id 1 started
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2070 writeChunk - DFSClient writeChunk allocating new packet seqno=0, src=/sdzw/hello.txt, packetSize=65532, chunksPerPacket=127, bytesCurBlock=0
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 666 run - Allocating new block
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 1
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 1
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: addBlock {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_1605974099_1" fileId: 77963}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: addBlock took 12ms
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: addBlock {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750887 generationStamp: 10067 numBytes: 0 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791293973 remaining: 886263259302 blockPoolUsed: 791293973 lastUpdate: 1481352338252 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1545 createBlockOutputStream - pipeline = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1777 createSocketForPipeline - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1786 createSocketForPipeline - Send buf size 131072
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #2
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #2
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 8ms
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750887
      generationStamp: 10067
      numBytes: 134217728
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_1605974099_1"
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 1
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false

2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750887_10067 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 12
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 0 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750887_10067 sending packet packet seqno: 1 offsetInBlock: 12 lastPacketInBlock: true lastByteOffsetInBlock: 12
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 1 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: complete {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_1605974099_1" last { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750887 generationStamp: 10067 numBytes: 12 } fileId: 77963}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #3
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #3
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: complete took 11ms
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: complete {result: true}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getBlockLocations {src: "/sdzw/hello.txt" offset: 0 length: 1342177280}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #4
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #4
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getBlockLocations took 33ms
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getBlockLocations {locations { fileLength: 12 blocks { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750887 generationStamp: 10067 numBytes: 12 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791293973 remaining: 886263259302 blockPoolUsed: 791293973 lastUpdate: 1481352338252 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } underConstruction: false lastBlock { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750887 generationStamp: 10067 numBytes: 12 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791293973 remaining: 886263259302 blockPoolUsed: 791293973 lastUpdate: 1481352338252 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } isLastBlockComplete: true }}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 307 fetchLocatedBlocksAndGetLastBlockLength - newInfo = LocatedBlocks{
  fileLength=12
  underConstruction=false
  blocks=[LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750887_10067; getBlockSize()=12; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750887_10067; getBlockSize()=12; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}
  isLastBlockComplete=true}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 1073 getBestNodeDNAddrPair - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 745 getRemoteBlockReaderFromTcp - BlockReaderFactory(fileName=/sdzw/hello.txt, block=BP-410674713-192.169.77.211-1480733607425:blk_1073750887_10067): trying to create a remote block reader from a TCP socket
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #5
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #5
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 9ms
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 841 nextTcpPeer - nextTcpPeer: created newConnectedPeer NioInetPeer(Socket[addr=/192.169.77.211,port=50010,localport=52494])
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpReadBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750887
      generationStamp: 10067
      numBytes: 12
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_1985880738_1"
}
offset: 0
len: 12
sendChecksums: true
cachingStrategy {
}

2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.hdfs.DFSClient 1115 isLocalAddress - Address /192.169.77.211:50010 is not local
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 145 read - Starting read #25738494-c5a7-41f0-baf3-1c020081c5c1 file /sdzw/hello.txt from datanode yingji
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 16 headerLen = 25
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 214 readNextPacket - DFSClient readNextPacket got header PacketHeader with packetLen=16 header data: offsetInBlock: 0
seqno: 0
lastPacketInBlock: false
dataLen: 12

2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 285 readTrailingEmptyPacket - Reading empty packet at end of read
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 0 headerLen = 25
2016-12-10 at 14:46:09 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 163 read - Finishing read #25738494-c5a7-41f0-baf3-1c020081c5c1
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 14:46:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:50:07 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:50:07 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:50:08 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:50:08 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:50:08 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:50:08 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:50:08 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:50:08 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:50:08 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:50:08 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:50:08 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:50:08 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:50:08 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 14:50:08 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:50:09 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:50:09 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:50:09 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 14:50:09 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: create {src: "/sdzw/hello.txt" masked { perm: 420 } clientName: "DFSClient_NONMAPREDUCE_498851880_1" createFlag: 3 createParent: true replication: 3 blockSize: 134217728 cryptoProtocolVersion: ENCRYPTION_ZONES}
2016-12-10 at 14:50:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 14:50:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 14:50:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 14:50:09 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: create took 471ms
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: create {fs { fileType: IS_FILE path: "" length: 0 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481352579565 access_time: 1481352579565 block_replication: 3 blocksize: 134217728 fileId: 77992 childrenNum: 0 storagePolicy: 0 }}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hello.txt, chunkSize=516, chunksPerPacket=127, packetSize=65532
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2070 writeChunk - DFSClient writeChunk allocating new packet seqno=0, src=/sdzw/hello.txt, packetSize=65532, chunksPerPacket=127, bytesCurBlock=0
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_498851880_1] with renew id 1 started
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 666 run - Allocating new block
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 1
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 1
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: addBlock {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_498851880_1" fileId: 77992}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: addBlock took 19ms
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: addBlock {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750892 generationStamp: 10072 numBytes: 0 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302144 remaining: 886263259302 blockPoolUsed: 791302144 lastUpdate: 1481352578309 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1545 createBlockOutputStream - pipeline = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1777 createSocketForPipeline - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1786 createSocketForPipeline - Send buf size 131072
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #2
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #2
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 6ms
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750892
      generationStamp: 10072
      numBytes: 134217728
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_498851880_1"
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 1
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false

2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750892_10072 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 12
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 0 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750892_10072 sending packet packet seqno: 1 offsetInBlock: 12 lastPacketInBlock: true lastByteOffsetInBlock: 12
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 1 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 587 endBlock - Closing old block BP-410674713-192.169.77.211-1480733607425:blk_1073750892_10072
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: complete {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_498851880_1" last { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750892 generationStamp: 10072 numBytes: 12 } fileId: 77992}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #3
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #3
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: complete took 9ms
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: complete {result: true}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getBlockLocations {src: "/sdzw/hello.txt" offset: 0 length: 1342177280}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #4
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #4
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getBlockLocations took 13ms
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getBlockLocations {locations { fileLength: 12 blocks { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750892 generationStamp: 10072 numBytes: 12 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302144 remaining: 886263259302 blockPoolUsed: 791302144 lastUpdate: 1481352578309 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } underConstruction: false lastBlock { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750892 generationStamp: 10072 numBytes: 12 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302144 remaining: 886263259302 blockPoolUsed: 791302144 lastUpdate: 1481352578309 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } isLastBlockComplete: true }}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 307 fetchLocatedBlocksAndGetLastBlockLength - newInfo = LocatedBlocks{
  fileLength=12
  underConstruction=false
  blocks=[LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750892_10072; getBlockSize()=12; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750892_10072; getBlockSize()=12; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}
  isLastBlockComplete=true}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 1073 getBestNodeDNAddrPair - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 745 getRemoteBlockReaderFromTcp - BlockReaderFactory(fileName=/sdzw/hello.txt, block=BP-410674713-192.169.77.211-1480733607425:blk_1073750892_10072): trying to create a remote block reader from a TCP socket
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #5
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #5
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 4ms
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 841 nextTcpPeer - nextTcpPeer: created newConnectedPeer NioInetPeer(Socket[addr=/192.169.77.211,port=50010,localport=52502])
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpReadBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750892
      generationStamp: 10072
      numBytes: 12
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-1163142937_1"
}
offset: 0
len: 12
sendChecksums: true
cachingStrategy {
}

2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.hdfs.DFSClient 1115 isLocalAddress - Address /192.169.77.211:50010 is not local
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 145 read - Starting read #98e1d57c-319d-405c-85f5-fcf322ad67b7 file /sdzw/hello.txt from datanode yingji
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 16 headerLen = 25
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 214 readNextPacket - DFSClient readNextPacket got header PacketHeader with packetLen=16 header data: offsetInBlock: 0
seqno: 0
lastPacketInBlock: false
dataLen: 12

2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 285 readTrailingEmptyPacket - Reading empty packet at end of read
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 0 headerLen = 25
2016-12-10 at 14:50:10 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 163 read - Finishing read #98e1d57c-319d-405c-85f5-fcf322ad67b7
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 14:50:10 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 14:53:29 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:53:29 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:53:29 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:53:29 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:53:30 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:43) [bin/:?]

2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:53:30 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:53:30 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:53:30 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:53:30 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:53:30 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:53:30 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:53:31 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:53:31 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 14:53:31 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:53:31 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 14:53:32 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: create {src: "/sdzw/hello.txt" masked { perm: 420 } clientName: "DFSClient_NONMAPREDUCE_-567597779_1" createFlag: 3 createParent: true replication: 3 blockSize: 134217728 cryptoProtocolVersion: ENCRYPTION_ZONES}
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: create took 410ms
2016-12-10 at 14:53:32 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: create {fs { fileType: IS_FILE path: "" length: 0 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481352782261 access_time: 1481352782261 block_replication: 3 blocksize: 134217728 fileId: 78024 childrenNum: 0 storagePolicy: 0 }}
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hello.txt, chunkSize=516, chunksPerPacket=127, packetSize=65532
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-567597779_1] with renew id 1 started
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2070 writeChunk - DFSClient writeChunk allocating new packet seqno=0, src=/sdzw/hello.txt, packetSize=65532, chunksPerPacket=127, bytesCurBlock=0
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 1
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 666 run - Allocating new block
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 1
2016-12-10 at 14:53:32 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: addBlock {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_-567597779_1" fileId: 78024}
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: addBlock took 12ms
2016-12-10 at 14:53:32 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: addBlock {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10077 numBytes: 0 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302144 remaining: 886263259302 blockPoolUsed: 791302144 lastUpdate: 1481352782321 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1545 createBlockOutputStream - pipeline = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1777 createSocketForPipeline - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1786 createSocketForPipeline - Send buf size 131072
2016-12-10 at 14:53:32 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #2
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #2
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 6ms
2016-12-10 at 14:53:32 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 14:53:32 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750897
      generationStamp: 10077
      numBytes: 134217728
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-567597779_1"
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 1
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false

2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750897_10077 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 6
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 0 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750897_10077 sending packet packet seqno: 1 offsetInBlock: 6 lastPacketInBlock: true lastByteOffsetInBlock: 6
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 1 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: complete {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_-567597779_1" last { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10077 numBytes: 6 } fileId: 78024}
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #3
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #3
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: complete took 9ms
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: complete {result: true}
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getBlockLocations {src: "/sdzw/hello.txt" offset: 0 length: 1342177280}
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #4
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #4
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getBlockLocations took 35ms
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getBlockLocations {locations { fileLength: 6 blocks { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10077 numBytes: 6 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302144 remaining: 886263259302 blockPoolUsed: 791302144 lastUpdate: 1481352782321 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } underConstruction: false lastBlock { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10077 numBytes: 6 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302144 remaining: 886263259302 blockPoolUsed: 791302144 lastUpdate: 1481352782321 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } isLastBlockComplete: true }}
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 307 fetchLocatedBlocksAndGetLastBlockLength - newInfo = LocatedBlocks{
  fileLength=6
  underConstruction=false
  blocks=[LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750897_10077; getBlockSize()=6; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750897_10077; getBlockSize()=6; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}
  isLastBlockComplete=true}
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 1073 getBestNodeDNAddrPair - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 745 getRemoteBlockReaderFromTcp - BlockReaderFactory(fileName=/sdzw/hello.txt, block=BP-410674713-192.169.77.211-1480733607425:blk_1073750897_10077): trying to create a remote block reader from a TCP socket
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #5
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #5
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 14ms
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 841 nextTcpPeer - nextTcpPeer: created newConnectedPeer NioInetPeer(Socket[addr=/192.169.77.211,port=50010,localport=52510])
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpReadBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750897
      generationStamp: 10077
      numBytes: 6
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_388663861_1"
}
offset: 0
len: 6
sendChecksums: true
cachingStrategy {
}

2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.hdfs.DFSClient 1115 isLocalAddress - Address /192.169.77.211:50010 is not local
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 145 read - Starting read #7d8ec165-02a3-4b7d-a1b9-d0df115a5161 file /sdzw/hello.txt from datanode yingji
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 10 headerLen = 25
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 214 readNextPacket - DFSClient readNextPacket got header PacketHeader with packetLen=10 header data: offsetInBlock: 0
seqno: 0
lastPacketInBlock: false
dataLen: 6

2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 285 readTrailingEmptyPacket - Reading empty packet at end of read
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 0 headerLen = 25
2016-12-10 at 14:53:33 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 163 read - Finishing read #7d8ec165-02a3-4b7d-a1b9-d0df115a5161
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 14:53:33 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 14:57:37 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 14:57:37 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:17) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:44) [bin/:?]

2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 14:57:38 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 14:57:38 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 14:57:38 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 14:57:38 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 14:57:38 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 14:57:38 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:57:40 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 14:57:40 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 14:57:41 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: append {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_-236432157_1"}
2016-12-10 at 14:57:41 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 14:57:41 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 14:57:41 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 14:57:41 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 14:57:41 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 14:57:41 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: append took 1298ms
2016-12-10 at 14:57:41 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: append {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10077 numBytes: 6 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302138 remaining: 886263259302 blockPoolUsed: 791302138 lastUpdate: 1481353028368 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } stat { fileType: IS_FILE path: "" length: 6 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481352782643 access_time: 1481352782261 block_replication: 3 blocksize: 134217728 fileId: 78024 childrenNum: 0 storagePolicy: 0 }}
2016-12-10 at 14:57:41 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hello.txt, chunkSize=510, chunksPerPacket=1, packetSize=510
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-236432157_1] with renew id 1 started
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 0
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 672 run - Append to block BP-410674713-192.169.77.211-1480733607425:blk_1073750897_10077
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1188 addDatanode2ExistingPipeline - lastAckedSeqno = -1
2016-12-10 at 14:57:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getAdditionalDatanode {src: "/sdzw/hello.txt" blk { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10077 numBytes: 6 } existings { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302138 remaining: 886263259302 blockPoolUsed: 791302138 lastUpdate: 1481353028368 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } numAdditionalNodes: 1 clientName: "DFSClient_NONMAPREDUCE_-236432157_1" existingStorageUuids: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" fileId: 78024}
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getAdditionalDatanode took 19ms
2016-12-10 at 14:57:42 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getAdditionalDatanode {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10077 numBytes: 6 } offset: 18446744073709551615 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302138 remaining: 886263259302 blockPoolUsed: 791302138 lastUpdate: 1481353031365 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-10 at 14:57:42 CST WARN  org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 790 run - DataStreamer Exception java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]], original=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:674) [hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]

2016-12-10 at 14:57:42 CST ERROR org.apache.hadoop.hdfs.DFSClient 970 closeAllFilesBeingWritten - Failed to close inode 78024 java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]], original=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:674) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]

2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 14:57:42 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 15:00:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 15:00:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 15:00:47 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 15:00:47 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 15:00:48 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:18) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:45) [bin/:?]

2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 15:00:48 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 15:00:48 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 15:00:48 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 15:00:48 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 15:00:48 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 15:00:48 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 15:00:49 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 15:00:49 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 15:00:49 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 15:00:50 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: append {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_-1655696586_1"}
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 15:00:50 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 238 invoke - 1: Exception <- yingji/192.169.77.211:8020: append {org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.RecoveryInProgressException): Failed to close file /sdzw/hello.txt. Lease recovery is in progress. Try again later.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:3113)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2905)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:3189)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:3153)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:612)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.append(AuthorizationProviderProxyClientProtocol.java:125)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:414)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)
}
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 15:00:50 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 15:08:46 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.Test.main(Test.java:20) [bin/:?]

2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 15:08:46 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 15:08:47 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 15:08:47 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 15:08:47 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 15:08:47 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 15:08:47 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 15:08:47 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 15:08:47 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 15:08:47 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 15:08:47 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 15:08:47 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 15:08:47 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 15:08:47 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:08:48 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 15:08:48 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 15:08:48 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:08:48 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:08:48 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:08:48 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 15:09:02 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 15:09:02 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.Test.main(Test.java:20) [bin/:?]

2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 15:09:03 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 15:09:03 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 15:09:03 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 15:09:03 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 15:09:03 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 15:09:03 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:09:04 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 15:09:04 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 15:09:04 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:09:04 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:09:04 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:09:04 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 15:09:41 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.Test.main(Test.java:20) [bin/:?]

2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 15:09:41 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 15:09:42 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 15:09:42 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 15:09:42 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 15:09:42 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 15:09:42 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 15:09:42 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:09:43 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 15:09:43 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 15:09:43 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: append {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_58126363_1"}
2016-12-10 at 15:09:43 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 15:09:43 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 15:09:43 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 15:09:43 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 15:09:43 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 15:09:43 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: append took 701ms
2016-12-10 at 15:09:43 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: append {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10085 numBytes: 6 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302144 remaining: 886262735014 blockPoolUsed: 791302144 lastUpdate: 1481353751525 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } stat { fileType: IS_FILE path: "" length: 6 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481353220423 access_time: 1481352782261 block_replication: 3 blocksize: 134217728 fileId: 78024 childrenNum: 0 storagePolicy: 0 }}
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hello.txt, chunkSize=510, chunksPerPacket=1, packetSize=510
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_58126363_1] with renew id 1 started
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2070 writeChunk - DFSClient writeChunk allocating new packet seqno=0, src=/sdzw/hello.txt, packetSize=510, chunksPerPacket=1, bytesCurBlock=6
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2089 writeChunk - DFSClient writeChunk packet full seqno=0, src=/sdzw/hello.txt, bytesCurBlock=22, blockSize=134217728, appendChunk=true
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 672 run - Append to block BP-410674713-192.169.77.211-1480733607425:blk_1073750897_10085
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1188 addDatanode2ExistingPipeline - lastAckedSeqno = -1
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 1
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 1
2016-12-10 at 15:09:44 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getAdditionalDatanode {src: "/sdzw/hello.txt" blk { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10085 numBytes: 6 } existings { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302144 remaining: 886262735014 blockPoolUsed: 791302144 lastUpdate: 1481353751525 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } numAdditionalNodes: 1 clientName: "DFSClient_NONMAPREDUCE_58126363_1" existingStorageUuids: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" fileId: 78024}
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getAdditionalDatanode took 7ms
2016-12-10 at 15:09:44 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getAdditionalDatanode {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10085 numBytes: 6 } offset: 18446744073709551615 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791302144 remaining: 886262735014 blockPoolUsed: 791302144 lastUpdate: 1481353751525 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-10 at 15:09:44 CST WARN  org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 790 run - DataStreamer Exception java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]], original=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:674) [hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]

2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 15:09:44 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 15:13:13 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.Test.main(Test.java:20) [bin/:?]

2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 15:13:13 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 15:13:14 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 15:13:14 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 15:13:14 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 15:13:14 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 15:13:14 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 15:13:14 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 15:13:14 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 15:13:14 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 15:13:14 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 15:13:14 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 15:13:14 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 15:13:14 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 15:13:15 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: append {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_-2101608571_1"}
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 15:13:15 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 238 invoke - 1: Exception <- yingji/192.169.77.211:8020: append {org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.RecoveryInProgressException): Failed to close file /sdzw/hello.txt. Lease recovery is in progress. Try again later.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:3113)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2905)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:3189)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:3153)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:612)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.append(AuthorizationProviderProxyClientProtocol.java:125)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:414)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)
}
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 15:13:15 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 15:29:11 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 15:29:11 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.Test.main(Test.java:20) [bin/:?]

2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 15:29:12 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 15:29:12 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 15:29:12 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 15:29:12 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 15:29:12 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 15:29:12 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:29:13 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 15:29:13 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 15:29:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: append {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_-287922534_1"}
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: append took 654ms
2016-12-10 at 15:29:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: append {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10097 numBytes: 6 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791310336 remaining: 886394822739 blockPoolUsed: 791310336 lastUpdate: 1481354923272 xceiverCount: 4 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } stat { fileType: IS_FILE path: "" length: 6 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481353966102 access_time: 1481352782261 block_replication: 3 blocksize: 134217728 fileId: 78024 childrenNum: 0 storagePolicy: 0 }}
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hello.txt, chunkSize=510, chunksPerPacket=1, packetSize=510
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-287922534_1] with renew id 1 started
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2070 writeChunk - DFSClient writeChunk allocating new packet seqno=0, src=/sdzw/hello.txt, packetSize=510, chunksPerPacket=1, bytesCurBlock=6
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2089 writeChunk - DFSClient writeChunk packet full seqno=0, src=/sdzw/hello.txt, bytesCurBlock=22, blockSize=134217728, appendChunk=true
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 672 run - Append to block BP-410674713-192.169.77.211-1480733607425:blk_1073750897_10097
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1188 addDatanode2ExistingPipeline - lastAckedSeqno = -1
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 1
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 1
2016-12-10 at 15:29:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getAdditionalDatanode {src: "/sdzw/hello.txt" blk { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10097 numBytes: 6 } existings { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791310336 remaining: 886394822739 blockPoolUsed: 791310336 lastUpdate: 1481354923272 xceiverCount: 4 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } numAdditionalNodes: 1 clientName: "DFSClient_NONMAPREDUCE_-287922534_1" existingStorageUuids: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" fileId: 78024}
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getAdditionalDatanode took 36ms
2016-12-10 at 15:29:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getAdditionalDatanode {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750897 generationStamp: 10097 numBytes: 6 } offset: 18446744073709551615 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791310336 remaining: 886394822739 blockPoolUsed: 791310336 lastUpdate: 1481354923272 xceiverCount: 4 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-10 at 15:29:14 CST WARN  org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 790 run - DataStreamer Exception java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]], original=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:674) [hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]

2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 15:29:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 15:29:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 15:29:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 15:29:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 15:29:53 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 15:29:54 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:18) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:45) [bin/:?]

2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 15:29:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 15:29:54 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 15:29:54 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 15:29:54 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 15:29:54 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 15:29:54 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 15:29:55 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 15:29:55 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 15:29:55 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 15:29:55 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 15:29:55 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 15:29:55 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 15:29:55 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 15:29:56 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: append {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_-1064773508_1"}
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 15:29:56 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 238 invoke - 1: Exception <- yingji/192.169.77.211:8020: append {org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to create file [/sdzw/hello.txt] for [DFSClient_NONMAPREDUCE_-1064773508_1] for client [192.169.144.55], because this file is already being created by [DFSClient_NONMAPREDUCE_-287922534_1] on [192.169.144.55]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:3124)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2905)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:3189)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:3153)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:612)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.append(AuthorizationProviderProxyClientProtocol.java:125)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:414)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)
}
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 15:29:56 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-10 at 15:31:28 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-10 at 15:31:28 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:18) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:45) [bin/:?]

2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-10 at 15:31:29 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-10 at 15:31:29 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-10 at 15:31:29 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-10 at 15:31:29 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-10 at 15:31:29 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-10 at 15:31:29 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:31:30 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-10 at 15:31:30 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 15:31:30 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: create {src: "/sdzw/hello.txt" masked { perm: 420 } clientName: "DFSClient_NONMAPREDUCE_265678658_1" createFlag: 3 createParent: true replication: 3 blockSize: 134217728 cryptoProtocolVersion: ENCRYPTION_ZONES}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: create took 489ms
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: create {fs { fileType: IS_FILE path: "" length: 0 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481355061012 access_time: 1481355061012 block_replication: 3 blocksize: 134217728 fileId: 78325 childrenNum: 0 storagePolicy: 0 }}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hello.txt, chunkSize=516, chunksPerPacket=127, packetSize=65532
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_265678658_1] with renew id 1 started
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2070 writeChunk - DFSClient writeChunk allocating new packet seqno=0, src=/sdzw/hello.txt, packetSize=65532, chunksPerPacket=127, bytesCurBlock=0
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 666 run - Allocating new block
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 1
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 1
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: addBlock {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_265678658_1" fileId: 78325}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: addBlock took 10ms
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: addBlock {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750935 generationStamp: 10117 numBytes: 0 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791310336 remaining: 886394822739 blockPoolUsed: 791310336 lastUpdate: 1481355058320 xceiverCount: 4 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1545 createBlockOutputStream - pipeline = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1777 createSocketForPipeline - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1786 createSocketForPipeline - Send buf size 131072
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #2
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #2
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 8ms
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750935
      generationStamp: 10117
      numBytes: 134217728
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_265678658_1"
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 1
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false

2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750935_10117 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 6
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 0 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073750935_10117 sending packet packet seqno: 1 offsetInBlock: 6 lastPacketInBlock: true lastByteOffsetInBlock: 6
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 1 reply: 0 downstreamAckTimeNanos: 0
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: complete {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_265678658_1" last { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750935 generationStamp: 10117 numBytes: 6 } fileId: 78325}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #3
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #3
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: complete took 8ms
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: complete {result: true}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getBlockLocations {src: "/sdzw/hello.txt" offset: 0 length: 1342177280}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #4
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #4
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getBlockLocations took 10ms
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getBlockLocations {locations { fileLength: 6 blocks { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750935 generationStamp: 10117 numBytes: 6 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791310336 remaining: 886260605011 blockPoolUsed: 791310336 lastUpdate: 1481355061320 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } underConstruction: false lastBlock { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073750935 generationStamp: 10117 numBytes: 6 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791310336 remaining: 886260605011 blockPoolUsed: 791310336 lastUpdate: 1481355061320 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } isLastBlockComplete: true }}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 307 fetchLocatedBlocksAndGetLastBlockLength - newInfo = LocatedBlocks{
  fileLength=6
  underConstruction=false
  blocks=[LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750935_10117; getBlockSize()=6; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073750935_10117; getBlockSize()=6; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}
  isLastBlockComplete=true}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 1073 getBestNodeDNAddrPair - Connecting to datanode 192.169.77.211:50010
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 745 getRemoteBlockReaderFromTcp - BlockReaderFactory(fileName=/sdzw/hello.txt, block=BP-410674713-192.169.77.211-1480733607425:blk_1073750935_10117): trying to create a remote block reader from a TCP socket
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #5
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #5
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 5ms
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 841 nextTcpPeer - nextTcpPeer: created newConnectedPeer NioInetPeer(Socket[addr=/192.169.77.211,port=50010,localport=53198])
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpReadBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073750935
      generationStamp: 10117
      numBytes: 6
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-15997976_1"
}
offset: 0
len: 6
sendChecksums: true
cachingStrategy {
}

2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.hdfs.DFSClient 1115 isLocalAddress - Address /192.169.77.211:50010 is not local
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 145 read - Starting read #505f4330-13bf-4b5a-a619-c67c57258d5f file /sdzw/hello.txt from datanode yingji
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 10 headerLen = 25
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 214 readNextPacket - DFSClient readNextPacket got header PacketHeader with packetLen=10 header data: offsetInBlock: 0
seqno: 0
lastPacketInBlock: false
dataLen: 6

2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 285 readTrailingEmptyPacket - Reading empty packet at end of read
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 0 headerLen = 25
2016-12-10 at 15:31:31 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 163 read - Finishing read #505f4330-13bf-4b5a-a619-c67c57258d5f
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@207b8649
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-10 at 15:31:31 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-12 at 09:46:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-12 at 09:46:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-12 at 09:46:53 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-12 at 09:46:53 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-12 at 09:46:53 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-12 at 09:46:53 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-12 at 09:46:53 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-12 at 09:46:53 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-12 at 09:46:53 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-12 at 09:46:53 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-12 at 09:46:53 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-12 at 09:46:53 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-12 at 09:46:54 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:18) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:45) [bin/:?]

2016-12-12 at 09:46:54 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-12 at 09:46:54 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-12 at 09:46:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-12 at 09:46:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-12 at 09:46:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-12 at 09:46:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-12 at 09:46:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-12 at 09:46:54 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-12 at 09:46:55 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-12 at 09:46:55 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-12 at 09:46:55 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-12 at 09:46:55 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-12 at 09:46:55 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-12 at 09:46:55 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-12 at 09:46:55 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-12 at 09:46:55 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-12 at 09:46:55 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-12 at 09:46:55 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-12 at 09:46:55 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-12 at 09:46:55 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 09:46:56 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-12 at 09:46:56 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-12 at 09:46:56 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-12 at 09:46:57 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: create {src: "/sdzw/hello.txt" masked { perm: 420 } clientName: "DFSClient_NONMAPREDUCE_-1642631849_1" createFlag: 3 createParent: true replication: 3 blockSize: 134217728 cryptoProtocolVersion: ENCRYPTION_ZONES}
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: create took 640ms
2016-12-12 at 09:46:57 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: create {fs { fileType: IS_FILE path: "" length: 0 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481507179361 access_time: 1481507179361 block_replication: 3 blocksize: 134217728 fileId: 99199 childrenNum: 0 storagePolicy: 0 }}
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hello.txt, chunkSize=516, chunksPerPacket=127, packetSize=65532
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1642631849_1] with renew id 1 started
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2070 writeChunk - DFSClient writeChunk allocating new packet seqno=0, src=/sdzw/hello.txt, packetSize=65532, chunksPerPacket=127, bytesCurBlock=0
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 1
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 666 run - Allocating new block
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 1
2016-12-12 at 09:46:57 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: addBlock {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_-1642631849_1" fileId: 99199}
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: addBlock took 22ms
2016-12-12 at 09:46:57 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: addBlock {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073753584 generationStamp: 12766 numBytes: 0 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791343104 remaining: 886239789222 blockPoolUsed: 791343104 lastUpdate: 1481507177608 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1545 createBlockOutputStream - pipeline = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1777 createSocketForPipeline - Connecting to datanode 192.169.77.211:50010
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1786 createSocketForPipeline - Send buf size 131072
2016-12-12 at 09:46:57 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #2
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #2
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 8ms
2016-12-12 at 09:46:57 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-12 at 09:46:57 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073753584
      generationStamp: 12766
      numBytes: 134217728
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-1642631849_1"
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 1
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false

2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073753584_12766 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 6
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 0 reply: 0 downstreamAckTimeNanos: 0
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073753584_12766 sending packet packet seqno: 1 offsetInBlock: 6 lastPacketInBlock: true lastByteOffsetInBlock: 6
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 1 reply: 0 downstreamAckTimeNanos: 0
2016-12-12 at 09:46:57 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: complete {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_-1642631849_1" last { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073753584 generationStamp: 12766 numBytes: 6 } fileId: 99199}
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #3
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #3
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: complete took 9ms
2016-12-12 at 09:46:57 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: complete {result: true}
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-12 at 09:46:57 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getBlockLocations {src: "/sdzw/hello.txt" offset: 0 length: 1342177280}
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #4
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #4
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getBlockLocations took 30ms
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getBlockLocations {locations { fileLength: 6 blocks { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073753584 generationStamp: 12766 numBytes: 6 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791343104 remaining: 886239789222 blockPoolUsed: 791343104 lastUpdate: 1481507177608 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } underConstruction: false lastBlock { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073753584 generationStamp: 12766 numBytes: 6 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791343104 remaining: 886239789222 blockPoolUsed: 791343104 lastUpdate: 1481507177608 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } isLastBlockComplete: true }}
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 307 fetchLocatedBlocksAndGetLastBlockLength - newInfo = LocatedBlocks{
  fileLength=6
  underConstruction=false
  blocks=[LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073753584_12766; getBlockSize()=6; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-410674713-192.169.77.211-1480733607425:blk_1073753584_12766; getBlockSize()=6; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]}
  isLastBlockComplete=true}
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.hdfs.DFSInputStream 1073 getBestNodeDNAddrPair - Connecting to datanode 192.169.77.211:50010
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 745 getRemoteBlockReaderFromTcp - BlockReaderFactory(fileName=/sdzw/hello.txt, block=BP-410674713-192.169.77.211-1480733607425:blk_1073753584_12766): trying to create a remote block reader from a TCP socket
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #5
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #5
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 9ms
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.hdfs.BlockReaderFactory 841 nextTcpPeer - nextTcpPeer: created newConnectedPeer NioInetPeer(Socket[addr=/192.169.77.211,port=50010,localport=54384])
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpReadBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073753584
      generationStamp: 12766
      numBytes: 6
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-1861771234_1"
}
offset: 0
len: 6
sendChecksums: true
cachingStrategy {
}

2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.hdfs.DFSClient 1115 isLocalAddress - Address /192.169.77.211:50010 is not local
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 145 read - Starting read #52d5b817-bbb9-4137-97ae-bc626d22ef4b file /sdzw/hello.txt from datanode yingji
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 10 headerLen = 25
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 214 readNextPacket - DFSClient readNextPacket got header PacketHeader with packetLen=10 header data: offsetInBlock: 0
seqno: 0
lastPacketInBlock: false
dataLen: 6

2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 285 readTrailingEmptyPacket - Reading empty packet at end of read
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver 151 doRead - readNextPacket: dataPlusChecksumLen = 0 headerLen = 25
2016-12-12 at 09:46:58 CST TRACE org.apache.hadoop.hdfs.RemoteBlockReader2 163 read - Finishing read #52d5b817-bbb9-4137-97ae-bc626d22ef4b
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@207b8649
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@207b8649
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-12 at 09:46:58 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-12 at 10:11:11 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-12 at 10:11:11 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-12 at 10:11:11 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-12 at 10:11:11 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-12 at 10:11:11 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-12 at 10:11:11 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-12 at 10:11:11 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-12 at 10:11:11 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-12 at 10:11:11 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-12 at 10:11:11 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-12 at 10:11:11 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-12 at 10:11:11 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:18) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:45) [bin/:?]

2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-12 at 10:11:12 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-12 at 10:11:12 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-12 at 10:11:12 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-12 at 10:11:12 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-12 at 10:11:12 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-12 at 10:11:12 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:11:13 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-12 at 10:11:13 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-12 at 10:11:13 CST DEBUG org.apache.hadoop.hdfs.DFSClient 1727 create - /sdzw/hello.txt: masked=rw-r--r--
2016-12-12 at 10:11:13 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: create {src: "/sdzw/hello.txt" masked { perm: 420 } clientName: "DFSClient_NONMAPREDUCE_2046402326_1" createFlag: 3 createParent: true replication: 3 blockSize: 134217728 cryptoProtocolVersion: ENCRYPTION_ZONES}
2016-12-12 at 10:11:13 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-12 at 10:11:13 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: create took 310ms
2016-12-12 at 10:11:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: create {fs { fileType: IS_FILE path: "" length: 0 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481508636129 access_time: 1481508636129 block_replication: 3 blocksize: 134217728 fileId: 99400 childrenNum: 0 storagePolicy: 0 }}
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hello.txt, chunkSize=516, chunksPerPacket=127, packetSize=65532
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_2046402326_1] with renew id 1 started
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2070 writeChunk - DFSClient writeChunk allocating new packet seqno=0, src=/sdzw/hello.txt, packetSize=65532, chunksPerPacket=127, bytesCurBlock=0
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 1
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 1
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 666 run - Allocating new block
2016-12-12 at 10:11:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: addBlock {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_2046402326_1" fileId: 99400}
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: addBlock took 11ms
2016-12-12 at 10:11:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: addBlock {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073753610 generationStamp: 12792 numBytes: 0 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791347200 remaining: 886239785126 blockPoolUsed: 791347200 lastUpdate: 1481508635945 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1545 createBlockOutputStream - pipeline = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1777 createSocketForPipeline - Connecting to datanode 192.169.77.211:50010
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1786 createSocketForPipeline - Send buf size 131072
2016-12-12 at 10:11:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getServerDefaults {}
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #2
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #2
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getServerDefaults took 4ms
2016-12-12 at 10:11:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getServerDefaults {serverDefaults { blockSize: 134217728 bytesPerChecksum: 512 writePacketSize: 65536 replication: 3 fileBufferSize: 4096 encryptDataTransfer: false trashInterval: 1440 checksumType: CHECKSUM_CRC32C }}
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient 245 send - SASL client skipping handshake in unsecured configuration for addr = /192.169.77.211, datanodeId = DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]
2016-12-12 at 10:11:14 CST TRACE org.apache.hadoop.hdfs.protocol.datatransfer.Sender 77 send - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-410674713-192.169.77.211-1480733607425"
      blockId: 1073753610
      generationStamp: 12792
      numBytes: 134217728
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_2046402326_1"
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 1
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false

2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073753610_12792 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 6
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 0 reply: 0 downstreamAckTimeNanos: 0
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 727 run - DataStreamer block BP-410674713-192.169.77.211-1480733607425:blk_1073753610_12792 sending packet packet seqno: 1 offsetInBlock: 6 lastPacketInBlock: true lastByteOffsetInBlock: 6
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor 980 run - DFSClient seqno: 1 reply: 0 downstreamAckTimeNanos: 0
2016-12-12 at 10:11:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: complete {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_2046402326_1" last { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073753610 generationStamp: 12792 numBytes: 6 } fileId: 99400}
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #3
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #3
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: complete took 9ms
2016-12-12 at 10:11:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: complete {result: true}
2016-12-12 at 10:11:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: rename {src: "/sdzw/hello.txt" dst: "/sdzw/hi.txt"}
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #4
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #4
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: rename took 9ms
2016-12-12 at 10:11:14 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: rename {result: true}
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-12 at 10:11:14 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-12 at 10:12:34 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:18) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:46) [bin/:?]

2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-12 at 10:12:34 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-12 at 10:12:34 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-12 at 10:12:34 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-12 at 10:12:34 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-12 at 10:12:34 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-12 at 10:12:34 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-12 at 10:12:35 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-12 at 10:12:35 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:12:35 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-12 at 10:12:35 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-12 at 10:12:36 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: append {src: "/sdzw/hello.txt" clientName: "DFSClient_NONMAPREDUCE_-1830811026_1"}
2016-12-12 at 10:12:36 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-12 at 10:12:36 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-12 at 10:12:36 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-12 at 10:12:36 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-12 at 10:12:36 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-12 at 10:12:36 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 238 invoke - 1: Exception <- yingji/192.169.77.211:8020: append {org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): failed to append to non-existent file /sdzw/hello.txt for client 192.169.144.55
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInternal(FSNamesystem.java:2892)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFileInt(FSNamesystem.java:3189)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:3153)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:612)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.append(AuthorizationProviderProxyClientProtocol.java:125)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:414)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)
}
2016-12-12 at 10:12:36 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:12:36 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:12:36 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:12:36 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-12 at 10:12:36 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-12 at 10:12:36 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory 42 newForField - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl 231 register - UgiMetrics, User and group related metrics
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.security.authentication.util.KerberosName 88 <clinit> - Kerberos krb5 configuration not found, setting default realm to empty
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.security.Groups 278 getUserToGroupsMappingService -  Creating new Groups object
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 46 <clinit> - Trying to load the custom-built native-hadoop library...
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 55 <clinit> - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.util.NativeCodeLoader 56 <clinit> - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-12-12 at 10:12:58 CST WARN  org.apache.hadoop.util.NativeCodeLoader 62 <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 41 <init> - Falling back to shell based
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback 45 <init> - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2016-12-12 at 10:12:58 CST DEBUG org.apache.hadoop.util.Shell 320 checkHadoopHome - Failed to detect a valid hadoop home directory java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:104) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:86) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:248) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:763) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:748) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:621) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2753) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2745) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611) [hadoop-common-2.6.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) [hadoop-common-2.6.0.jar:?]
	at hbase.com.cn.HDFSTest.WriteFile(HDFSTest.java:18) [bin/:?]
	at hbase.com.cn.HDFSTest.main(HDFSTest.java:46) [bin/:?]

2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.util.Shell 396 isSetsidSupported - setsid exited with exit code 0
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.security.Groups 91 <init> - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 209 login - hadoop login
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 144 commit - hadoop login commit
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 174 commit - using local user:UnixPrincipal: acer
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 180 commit - Using user: "UnixPrincipal: acer" with name acer
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule 190 commit - User entry: "acer"
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.security.UserGroupInformation 799 loginUserFromSubject - UGI loginUser:acer (auth:SIMPLE)
2016-12-12 at 10:12:59 CST DEBUG org.apache.htrace.core.Tracer$Builder 106 loadSamplers - sampler.classes = ; loaded no samplers
2016-12-12 at 10:12:59 CST TRACE org.apache.htrace.core.TracerId 134 <init> - ProcessID(fmt=%{tname}/%{ip}): computed process ID of "FSClient/172.17.0.1"
2016-12-12 at 10:12:59 CST TRACE org.apache.htrace.core.TracerPool 262 addTracer - TracerPool(Global): adding tracer Tracer(FSClient/172.17.0.1)
2016-12-12 at 10:12:59 CST DEBUG org.apache.htrace.core.Tracer$Builder 128 loadSpanReceivers - span.receiver.classes = ; loaded no span receivers
2016-12-12 at 10:12:59 CST TRACE org.apache.htrace.core.Tracer$Builder 165 build - Created Tracer(FSClient/172.17.0.1) for FSClient
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 455 <init> - dfs.client.use.legacy.blockreader.local = false
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 458 <init> - dfs.client.read.shortcircuit = false
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 461 <init> - dfs.client.domain.socket.data.traffic = false
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.hdfs.DFSClient$Conf 464 <init> - dfs.domain.socket.path = 
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.io.retry.RetryUtils 74 getDefaultRetryPolicy - multipleLinearRandomRetry = null
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.ipc.Server 233 registerProtocolEngine - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@368247b9
2016-12-12 at 10:12:59 CST DEBUG org.apache.hadoop.ipc.ClientCache 63 getClient - getting client out of cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:13:00 CST DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory 110 <init> - Both short-circuit local reads and UNIX domain socket are disabled.
2016-12-12 at 10:13:00 CST DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil 183 getSaslPropertiesResolver - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2016-12-12 at 10:13:00 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 1: Call -> yingji/192.169.77.211:8020: append {src: "/sdzw/hi.txt" clientName: "DFSClient_NONMAPREDUCE_-1468346287_1"}
2016-12-12 at 10:13:00 CST DEBUG org.apache.hadoop.ipc.Client$Connection 427 <init> - The ping interval is 60000 ms.
2016-12-12 at 10:13:00 CST DEBUG org.apache.hadoop.ipc.Client$Connection 697 setupIOstreams - Connecting to yingji/192.169.77.211:8020
2016-12-12 at 10:13:00 CST DEBUG org.apache.hadoop.ipc.Client$Connection 961 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: starting, having connections 1
2016-12-12 at 10:13:00 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #0
2016-12-12 at 10:13:00 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #0
2016-12-12 at 10:13:00 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: append took 408ms
2016-12-12 at 10:13:00 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 1: Response <- yingji/192.169.77.211:8020: append {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073753610 generationStamp: 12792 numBytes: 6 } offset: 0 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791347200 remaining: 886239260838 blockPoolUsed: 791347200 lastUpdate: 1481508740968 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" } stat { fileType: IS_FILE path: "" length: 6 permission { perm: 420 } owner: "acer" group: "supergroup" modification_time: 1481508636434 access_time: 1481508636129 block_replication: 3 blocksize: 134217728 fileId: 99400 childrenNum: 0 storagePolicy: 0 }}
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1982 computePacketChunkSize - computePacketChunkSize: src=/sdzw/hi.txt, chunkSize=510, chunksPerPacket=1, packetSize=510
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.hdfs.LeaseRenewer$1 301 run - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1468346287_1] with renew id 1 started
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2070 writeChunk - DFSClient writeChunk allocating new packet seqno=0, src=/sdzw/hi.txt, packetSize=510, chunksPerPacket=1, bytesCurBlock=6
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2089 writeChunk - DFSClient writeChunk packet full seqno=0, src=/sdzw/hi.txt, bytesCurBlock=12, blockSize=134217728, appendChunk=true
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 0
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 672 run - Append to block BP-410674713-192.169.77.211-1480733607425:blk_1073753610_12792
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 1188 addDatanode2ExistingPipeline - lastAckedSeqno = -1
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 1996 queueCurrentPacket - Queued packet 1
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.hdfs.DFSOutputStream 2356 waitForAckedSeqno - Waiting for ack for: 1
2016-12-12 at 10:13:01 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 223 invoke - 14: Call -> yingji/192.169.77.211:8020: getAdditionalDatanode {src: "/sdzw/hi.txt" blk { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073753610 generationStamp: 12792 numBytes: 6 } existings { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791347200 remaining: 886239260838 blockPoolUsed: 791347200 lastUpdate: 1481508740968 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } numAdditionalNodes: 1 clientName: "DFSClient_NONMAPREDUCE_-1468346287_1" existingStorageUuids: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" fileId: 99400}
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.ipc.Client$Connection$3 1024 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer sending #1
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1081 receiveRpcResponse - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer got value #1
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 253 invoke - Call: getAdditionalDatanode took 31ms
2016-12-12 at 10:13:01 CST TRACE org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker 268 invoke - 14: Response <- yingji/192.169.77.211:8020: getAdditionalDatanode {block { b { poolId: "BP-410674713-192.169.77.211-1480733607425" blockId: 1073753610 generationStamp: 12792 numBytes: 6 } offset: 18446744073709551615 locs { id { ipAddr: "192.169.77.211" hostName: "yingji" datanodeUuid: "30b46015-9e7a-482c-b240-a4e858a68384" xferPort: 50010 infoPort: 50075 ipcPort: 50020 infoSecurePort: 0 } capacity: 940327608320 dfsUsed: 791347200 remaining: 886239260838 blockPoolUsed: 791347200 lastUpdate: 1481508740968 xceiverCount: 6 location: "/default" adminState: NORMAL cacheCapacity: 346030080 cacheUsed: 0 } corrupt: false blockToken { identifier: "" password: "" kind: "" service: "" } isCached: false storageTypes: DISK storageIDs: "DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e" }}
2016-12-12 at 10:13:01 CST WARN  org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer 790 run - DataStreamer Exception java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]], original=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:674) [hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]

2016-12-12 at 10:13:01 CST ERROR org.apache.hadoop.hdfs.DFSClient 970 closeAllFilesBeingWritten - Failed to close inode 99400 java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]], original=[DatanodeInfoWithStorage[192.169.77.211:50010,DS-b8e28f0c-1c1b-4de1-bd35-aef2a29a0b7e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:674) ~[hadoop-hdfs-2.6.0-cdh5.7.0.jar:?]

2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.ipc.ClientCache 97 stopClient - stopping client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.ipc.ClientCache 103 stopClient - removing client from cache: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.ipc.ClientCache 110 stopClient - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7674f035
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.ipc.Client 1234 stop - Stopping client
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.ipc.Client$Connection 1184 close - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: closed
2016-12-12 at 10:13:01 CST DEBUG org.apache.hadoop.ipc.Client$Connection 979 run - IPC Client (198499365) connection to yingji/192.169.77.211:8020 from acer: stopped, remaining connections 0
